{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ad980",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict as odict\n",
    "from netCDF4 import Dataset\n",
    "from os.path import exists\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from matplotlib.ticker import EngFormatter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee27eae",
   "metadata": {},
   "source": [
    "# Instructions for Creating Histograms on a New Dataset\n",
    "\n",
    "To add a new dataset, follow these steps:\n",
    "\n",
    "1. Define the appropriate set of configurations for the dataset in the `info_fam` dictionary below. \n",
    "    \n",
    "    Let's assume your new data family's name is `\"01_cares\"`.\n",
    "\n",
    "2. Convert this notebook to a python script and run it like below:\n",
    "\n",
    "    ```bash\n",
    "    source ./activate mamba\n",
    "    jupytext --to py notebooks/n02_histdata.ipynb\n",
    "    NWORKERS=20\n",
    "    for MYRANK in $(seq 0 $((NWORKERS-1))); do \n",
    "        python notebooks/n02_histdata.py -f \"01_cares\" -r ${MYRANK} -s ${NWORKERS} &\n",
    "    done\n",
    "    wait\n",
    "    ```\n",
    "\n",
    "    Remember to specify a new `\"01_cares\"` dataset name and number of workers `NWORKERS`. \n",
    "\n",
    "    This step will generate `NWORKERS` files such as `f'{data_dir}'/02_masshist/04_caressamp_00.nc` to `f'{data_dir}'/02_masshist/04_caressamp_19.nc`.\n",
    "    `\n",
    "\n",
    "3. Come back to this notebook, and go all the way down to the \"Compiling All Data into a Single netCDF File\" section:\n",
    "\n",
    "    * Replace the `fam_data` from `None` to the new data family name `\"01_cares\"`.\n",
    "    \n",
    "    * Run the cell script to generate the compiled `f'{data_dir}'/02_masshist/04_caressamp.nc` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The following should be specified properly.\n",
    "data_dir = '../data'\n",
    "datalfs_dir = '/path/to/large/file/system/data_partnn'\n",
    "\n",
    "out_datadir, out_datalfsdir = data_dir, datalfs_dir\n",
    "\n",
    "args_datafamily, args_dryrun, args_belazy = '01_bwchi', False, True\n",
    "\n",
    "my_rank, n_workers = None, 1\n",
    "\n",
    "use_tqdm, tqdm = False, lambda itrtr: itrtr\n",
    "if use_tqdm and (my_rank == 0): \n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab37e678",
   "metadata": {
    "tags": [
     "active-py"
    ]
   },
   "source": [
    "use_argparse = True\n",
    "if use_argparse:\n",
    "    import argparse\n",
    "    my_parser = argparse.ArgumentParser()\n",
    "    my_parser.add_argument('-f', '--family', action='store', type=str, required=True)\n",
    "    my_parser.add_argument('-s', '--nodesize', action='store', type=int, default=1)\n",
    "    my_parser.add_argument('-r', '--noderank', action='store', type=int, default=0)\n",
    "    my_parser.add_argument('--dry-run', action='store_true')\n",
    "    my_parser.add_argument('--lazy', action='store_true')\n",
    "    args = my_parser.parse_args()\n",
    "    args_datafamily = args.family\n",
    "    args_nodesize = args.nodesize\n",
    "    args_noderank = args.noderank\n",
    "    args_dryrun = args.dry_run\n",
    "    args_belazy = args.lazy\n",
    "else:\n",
    "    args_datafamily = '01_cares'\n",
    "    args_dryrun = False\n",
    "    args_belazy = False\n",
    "    args_nodesize = 1\n",
    "    args_noderank = 0\n",
    "\n",
    "my_rank, n_workers = args_noderank, args_nodesize\n",
    "\n",
    "use_tqdm = True\n",
    "if use_tqdm and (my_rank == 0): \n",
    "    from tqdm import tqdm\n",
    "\n",
    "if args_dryrun and (my_rank == 0):\n",
    "    import tempfile\n",
    "    temp_datadir = tempfile.TemporaryDirectory()\n",
    "    temp_datalfsdir = tempfile.TemporaryDirectory()\n",
    "    print(f'>> [dry-run] Temporary output data dir placed at {temp_datadir.name}')\n",
    "    print(f'>> [dry-run] Temporary output data lfs dir placed at {temp_datalfsdir.name}')\n",
    "    out_datadir = temp_datadir.name\n",
    "    out_datalfsdir = temp_datalfsdir.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151e838",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_histdata(nc_fp, nc_path, snridx_nc, n_bins, diam_low, diam_high, diam_logbase, \n",
    "    chem_species_keep, lib='numpy', verbose=False):\n",
    "\n",
    "    if snridx_nc in (None, 'all'):\n",
    "        i_setstrt, i_setend = 0, None\n",
    "    else:\n",
    "        # The start indices for each dataset of particles. \n",
    "        # This is one-based (i.e., fortran-style indices).\n",
    "        i_setstrts = nc_fp.variables['part_start_index'][:] - 1\n",
    "\n",
    "        n_dsets = len(i_setstrts)\n",
    "        assert isinstance(snridx_nc, int), f'\"{snridx_nc}\" is not an integer index'\n",
    "\n",
    "        snridxpos_nc = snridx_nc + n_dsets if snridx_nc < 0 else snridx_nc\n",
    "        assert (snridxpos_nc < n_dsets) and (snridxpos_nc >= 0), dedent(f'''\n",
    "            There are only \"{n_dsets}\" start indices, and you're \n",
    "            trying to access the \"{snridx_nc}\"-th set of particles:\n",
    "                nc_path = {nc_path}\n",
    "                snridx_nc = {snridx_nc}\n",
    "                n_dsets = {n_dsets}''')\n",
    "        \n",
    "        i_setstrt = i_setstrts[snridxpos_nc]\n",
    "        if snridxpos_nc == (n_dsets - 1):\n",
    "            i_setend = None \n",
    "        else:\n",
    "            i_setend = i_setstrts[snridxpos_nc + 1]\n",
    "\n",
    "    # Getting the number of chemicals and the actual\n",
    "    n_chem_og, = nc_fp.variables['aero_species'].shape\n",
    "    chem_species_ogstr = nc_fp.variables['aero_species'].names\n",
    "    assert isinstance(chem_species_ogstr, str)\n",
    "\n",
    "    chem_species_og = chem_species_ogstr.split(',')\n",
    "    assert len(chem_species_og) == n_chem_og\n",
    "\n",
    "    # Keeping the specified subset of chemical species\n",
    "    assert isinstance(chem_species_keep, str)\n",
    "    if chem_species_keep == 'all':\n",
    "        # The number of kept chemical species\n",
    "        n_chem = n_chem_og\n",
    "        # The kept chemical species names list\n",
    "        chem_species = chem_species_og\n",
    "        # The kept chemical subset indices\n",
    "        i_chemkeep = slice(None, None, None)\n",
    "    else:\n",
    "        # The kept chemical species names list\n",
    "        chem_species = chem_species_keep.split(',')\n",
    "        # The number of kept chemical species\n",
    "        n_chem = len(chem_species)\n",
    "        # Sanity checks\n",
    "        for chm in chem_species:\n",
    "            assert chm in chem_species_og, dedent(f'''\n",
    "                The \"{chm}\" chemical specie could not be found in the input \n",
    "                file's chemical species:\n",
    "                    available chemical species: \"{chem_species_ogstr}\"''')\n",
    "        # The kept chemical subset indices\n",
    "        i_chemkeep = [chem_species_og.index(chm) for chm in chem_species]\n",
    "    \n",
    "    chem_species_str = ','.join(chem_species)\n",
    "    \n",
    "    # The 2-d mass array of the chemicals in particles\n",
    "    m_chmprt = nc_fp.variables['aero_particle_mass'][i_chemkeep, i_setstrt:i_setend]\n",
    "    n_part, = m_chmprt.shape[1:]\n",
    "    assert m_chmprt.shape == (n_chem, n_part)\n",
    "    assert m_chmprt.dtype == np.float64, m_chmprt.dtype\n",
    "\n",
    "    # The chemical density for each species in (kg/m^3)\n",
    "    rho_chem = nc_fp.variables['aero_density'][i_chemkeep].astype(np.float64)\n",
    "    assert rho_chem.shape == (n_chem,)\n",
    "    assert rho_chem.dtype == np.float64, rho_chem.dtype\n",
    "\n",
    "    # The importance weight of each particle\n",
    "    c_part = nc_fp.variables['aero_num_conc'][i_setstrt:i_setend]\n",
    "    assert c_part.shape == (n_part,)\n",
    "    assert c_part.dtype == np.float64, c_part.dtype\n",
    "\n",
    "    if lib == 'torch':\n",
    "        m_chmprt = torch.tensor(m_chmprt)\n",
    "        rho_chem = torch.tensor(rho_chem)\n",
    "        c_part = torch.tensor(c_part)\n",
    "    elif lib == 'numpy':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f'lib={lib} is not implemented')\n",
    "\n",
    "    # The volume of each chemical species within particles\n",
    "    v_chempart = m_chmprt / rho_chem.reshape(n_chem, 1)\n",
    "    assert v_chempart.shape == (n_chem, n_part)\n",
    "\n",
    "    # The volume of each particle\n",
    "    v_part = v_chempart.sum(axis=0)\n",
    "    assert v_part.shape == (n_part,)\n",
    "\n",
    "    # The diameter of each particle\n",
    "    d_part = (6 * v_part / np.pi) ** (1 / 3)\n",
    "    assert d_part.shape == (n_part,)\n",
    "\n",
    "    # The mass of each particle\n",
    "    m_part = m_chmprt.sum(axis=0)\n",
    "    assert m_part.shape == (n_part,)\n",
    "\n",
    "    # The normalized weight of chemicals within each particle\n",
    "    w_chmprt = m_chmprt / m_part.reshape(1, n_part)\n",
    "    assert w_chmprt.shape == (n_chem, n_part)\n",
    "\n",
    "    # The volume of each chemical species within particles\n",
    "    v_chempart = m_chmprt / rho_chem.reshape(n_chem, 1)\n",
    "    assert v_chempart.shape == (n_chem, n_part)\n",
    "\n",
    "    # The volume of each particle\n",
    "    v_part = v_chempart.sum(axis=0)\n",
    "    assert v_part.shape == (n_part,)\n",
    "\n",
    "    # The diameter of each particle\n",
    "    d_part = (6 * v_part / np.pi) ** (1 / 3)\n",
    "    assert d_part.shape == (n_part,)\n",
    "\n",
    "    # The mass of each particle\n",
    "    m_part = m_chmprt.sum(axis=0)\n",
    "    assert m_part.shape == (n_part,)\n",
    "\n",
    "    # The normalized weight of chemicals within each particle\n",
    "    w_chmprt = m_chmprt / m_part.reshape(1, n_part)\n",
    "    assert w_chmprt.shape == (n_chem, n_part)\n",
    "\n",
    "    # The log-dimeter logistics\n",
    "    logdiam_low, logdiam_high = np.log(diam_low) / diam_logbase, np.log(diam_high) / diam_logbase\n",
    "    if verbose and not (d_part >= diam_low).all():\n",
    "        print(f'\\n{nc_path} has diameters as small as {d_part.min()}.')\n",
    "    if verbose and not (d_part < diam_high).all():\n",
    "        print(f'\\n{nc_path} has diameters as large as {d_part.max()}.')\n",
    "\n",
    "    # The log-diameter of all particles\n",
    "    logd_part = np.log(d_part) / diam_logbase\n",
    "    assert logd_part.shape == (n_part,)\n",
    "\n",
    "    # The normalized log-dimater within the `[logdiam_high, logdiam_low]` range.\n",
    "    logdn_part = (logd_part - logdiam_low) / (logdiam_high - logdiam_low)\n",
    "    assert logdn_part.shape == (n_part,)\n",
    "\n",
    "    # The log-dimater bin of each particle\n",
    "    dbin_part = (logdn_part * n_bins)\n",
    "    dbin_part = (dbin_part.astype(np.int64) if lib == 'numpy'\n",
    "        else dbin_part.to(torch.long))\n",
    "    dbin_part[dbin_part >= n_bins] = n_bins - 1\n",
    "    dbin_part[dbin_part < 0] = 0\n",
    "    assert dbin_part.shape == (n_part,)\n",
    "\n",
    "    if lib == 'numpy':\n",
    "        # The number of particles histogram within each diamater bin\n",
    "        n_prthst = np.zeros(n_bins, np.int64)\n",
    "        np.add.at(n_prthst, dbin_part, c_part)\n",
    "        assert n_prthst.shape == (n_bins,)\n",
    "\n",
    "        # The total mass of particles within each diameter bin\n",
    "        m_prthst = np.zeros(n_bins, np.float64)\n",
    "        np.add.at(m_prthst, dbin_part, m_part * c_part)\n",
    "        assert m_prthst.shape == (n_bins,)\n",
    "\n",
    "        # The total mass of each chemical species in each diameter bin\n",
    "        m_chmprthst_ = np.zeros((n_bins, n_chem), np.float64)\n",
    "        np.add.at(m_chmprthst_, dbin_part, m_chmprt.T * c_part.reshape(n_part, 1))\n",
    "        assert m_chmprthst_.shape == (n_bins, n_chem)\n",
    "    elif lib == 'torch':\n",
    "        # The number of particles histogram within each diamater bin\n",
    "        n_prthst = torch.zeros(n_bins, dtype=c_part.dtype)\n",
    "        n_prthst.scatter_add_(dim=0, index=dbin_part, src=c_part)\n",
    "        assert n_prthst.shape == (n_bins,)\n",
    "\n",
    "        # The total mass of particles within each diameter bin\n",
    "        m_prthst = torch.zeros(n_bins, dtype=m_part.dtype)\n",
    "        m_prthst.scatter_add_(dim=0, index=dbin_part, src=m_part * c_part)\n",
    "        assert m_prthst.shape == (n_bins,)\n",
    "\n",
    "        # The total mass of each chemical species in each diameter bin\n",
    "        m_chmprthst_ = torch.zeros(n_bins, n_chem, dtype=m_part.dtype)\n",
    "        m_chmprthst_.scatter_add_(dim=0, index=dbin_part.reshape(n_part, 1), \n",
    "            src=m_chmprt.T * c_part.reshape(n_part, 1))\n",
    "        assert m_chmprthst_.shape == (n_bins, n_chem)\n",
    "    else:\n",
    "        raise ValueError(f'lib={lib} is not implemented')\n",
    "\n",
    "    # Making the mass data \"channels\"-compatible\n",
    "    m_chmprthst = m_chmprthst_.T\n",
    "    assert m_chmprthst.shape == (n_chem, n_bins)\n",
    "\n",
    "    if lib == 'torch':\n",
    "        m_chmprt = m_chmprt.detach().cpu().numpy()\n",
    "        rho_chem = rho_chem.detach().cpu().numpy()\n",
    "        c_part = c_part.detach().cpu().numpy()\n",
    "    elif lib == 'numpy':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f'lib={lib} is not implemented')\n",
    "\n",
    "    assert n_prthst.dtype == np.int64, n_prthst.dtype\n",
    "    assert m_prthst.dtype == np.float64, m_prthst.dtype\n",
    "    assert m_chmprthst.dtype == np.float64, m_chmprthst.dtype\n",
    "\n",
    "    out_dict = dict(n_prthst=n_prthst, m_prthst=m_prthst, \n",
    "        m_chmprthst=m_chmprthst, chem_species_str=chem_species_str)\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "def get_bwncpath(data_dir, data_tree, i_grid, n_grid, scnr_idx, t_idx):\n",
    "    n_x, n_y, n_z = n_grid\n",
    "    i_x, i_y, i_z = i_grid\n",
    "    assert scnr_idx == i_z + i_y * n_z + i_x * n_y * n_z\n",
    "\n",
    "    nc_path = f'{data_dir}/{data_tree}/scenario_{scnr_idx}/scenario_{scnr_idx}_0001_000000{t_idx+1:02d}.nc'\n",
    "    snridx_nc = 'all'\n",
    "    assert exists(nc_path), dedent(f'''\n",
    "        The BlueWater chi-sampling netCDF data file is missing:\n",
    "            nc_path = {nc_path}''')\n",
    "\n",
    "    return nc_path, snridx_nc\n",
    "\n",
    "def get_caresncpath(data_dir, data_tree, i_grid, n_grid, scnr_idx, t_idx):\n",
    "    n_x, n_y, n_z = n_grid\n",
    "    i_x, i_y, i_z = i_grid\n",
    "    assert scnr_idx == i_z + i_y * n_z + i_x * n_y * n_z\n",
    "\n",
    "    nc_path = f'{data_dir}/{data_tree}/{t_idx+1:02d}/cares_{i_x+1:03d}_{i_y+1:03d}_{t_idx+1:08d}.nc'\n",
    "    snridx_nc = i_z\n",
    "\n",
    "    if (t_idx != 3):\n",
    "        is_ncokay = True\n",
    "    elif (i_x < 94):\n",
    "        is_ncokay = True\n",
    "    elif (i_x == 94) and (i_y < 13):\n",
    "        is_ncokay = True\n",
    "    else:\n",
    "        is_ncokay = False\n",
    "    \n",
    "    if is_ncokay:\n",
    "        assert exists(nc_path), dedent(f'''\n",
    "            The CARES simulation netCDF data file is missing:\n",
    "                nc_path = {nc_path}''')\n",
    "    else:\n",
    "        nc_path, snridx_nc = get_caresncpath(data_dir, data_tree, i_grid, n_grid, scnr_idx, t_idx + 1)\n",
    "\n",
    "    return nc_path, snridx_nc\n",
    "\n",
    "# The chemical densities in the scenarios library\n",
    "chem2rho_bwchi = {'SO4': 1800.0, 'NO3': 1800.0, 'Cl': 2200.0, 'NH4': 1800.0, 'MSA': 1800.0, \n",
    "    'ARO1': 1400.0, 'ARO2': 1400.0, 'ALK1': 1400.0, 'OLE1': 1400.0, 'API1': 1400.0, 'API2': 1400.0, \n",
    "    'LIM1': 1400.0, 'LIM2': 1400.0, 'CO3': 2600.0, 'Na': 2200.0, 'Ca': 2600.0, 'OIN': 2600.0, \n",
    "    'OC': 1000.0, 'BC': 1800.0, 'MOC': 1000.0, 'H2O': 1000.0}\n",
    "\n",
    "# The chemical kappa values in the scenarios library\n",
    "chem2kappa_bwchi = {'SO4': 0.65, 'NO3': 0.65, 'Cl': 0.53, 'NH4': 0.65, 'MSA': 0.53, \n",
    "    'ARO1': 0.1, 'ARO2': 0.1, 'ALK1': 0.1, 'OLE1': 0.1, 'API1': 0.1, 'API2': 0.1, \n",
    "    'LIM1': 0.1, 'LIM2': 0.1, 'CO3': 0.53, 'Na': 0.53, 'Ca': 0.53, 'OIN': 0.001, \n",
    "    'OC': 0.001, 'BC': 0.0, 'MOC': 0.001, 'H2O': 0.0}\n",
    "\n",
    "# The optical wave-lengths and water's refraction index\n",
    "wvid2len = {f'{wvln * 1e9:g}nm': wvln for wvln in [300e-9, 400e-9, 550e-9, 600e-9, 1e-6]}\n",
    "h2o_refrs = {'300nm/H2O': (1.35+1.524e-08j), '400nm/H2O': (1.34+2.494e-09j), \n",
    "    '550nm/H2O': (1.33+0j), '600nm/H2O': (1.33+1.638e-09j), '1000nm/H2O': (1.33+3.128e-06j)}\n",
    "\n",
    "# The chemical refractive index values in the scenarios library\n",
    "chem2refr_bwchi1 = {'SO4': (1.5+0j), 'NO3': (1.5+0j), 'Cl': (1.5+0j), 'NH4': (1.5+0j), \n",
    "    'MSA': (1.43+0j), 'ARO1': (1.45+0j), 'ARO2': (1.45+0j), 'ALK1': (1.45+0j), 'OLE1': (1.45+0j), \n",
    "    'API1': (1.45+0j), 'API2': (1.45+0j), 'LIM1': (1.45+0j), 'LIM2': (1.45+0j), 'CO3': (1.5+0j), \n",
    "    'Na': (1.5+0j), 'Ca': (1.5+0j), 'OIN': (1.55+0.006j), 'OC': (1.45+0j), 'BC': (1.82+0.74j), \n",
    "    'MOC': (1.5+0j), 'H2O': None}\n",
    "chem2refr_bwchi = {f'{wvid}/{chem}': chmrfr for wvid in wvid2len \n",
    "    for chem, chmrfr in chem2refr_bwchi1.items()}\n",
    "chem2refr_bwchi.update(h2o_refrs)\n",
    "\n",
    "# The chemical densities in the CARES simulations\n",
    "chem2rho_cares = {'SO4': 1770.0, 'NO3': 1770.0, 'Cl': 1900.0, 'NH4': 1770.0, 'MSA': 1800.0, \n",
    "    'ARO1': 1400.0, 'ARO2': 1400.0, 'ALK1': 1400.0, 'OLE1': 1400.0, 'API1': 1000.0, 'API2': 1400.0, \n",
    "    'LIM1': 1400.0, 'LIM2': 1400.0, 'CO3': 2600.0, 'Na': 1900.0, 'Ca': 2600.0, 'OIN': 2600.0, \n",
    "    'OC': 1000.0, 'BC': 1700.0, 'H2O': 1000.0}\n",
    "\n",
    "# The chemical kappa values in the CARES simulations\n",
    "chem2kappa_cares = {'SO4': 0.65, 'NO3': 0.65, 'Cl': 1.28, 'NH4': 0.65, 'MSA': 0.53, \n",
    "    'ARO1': 0.1, 'ARO2': 0.1, 'ALK1': 0.1, 'OLE1': 0.1, 'API1': 0.1, 'API2': 0.1, \n",
    "    'LIM1': 0.1, 'LIM2': 0.1, 'CO3': 0.53, 'Na': 1.28, 'Ca': 0.53, 'OIN': 0.1, \n",
    "    'OC': 0.001, 'BC': 0.0, 'H2O': 0.0}\n",
    "\n",
    "# The chemical refraction indices in the CARES simulations\n",
    "chem2refr_cares1 = {'SO4': (1.5+0j), 'NO3': (1.5+0j), 'Cl': (1.5+0j), 'NH4': (1.5+0j), 'MSA': (1.43+0j), \n",
    "    'ARO1': (1.45+0j), 'ARO2': (1.45+0j), 'ALK1': (1.45+0j), 'OLE1': (1.45+0j), 'API1': (1.45+0j), \n",
    "    'API2': (1.45+0j), 'LIM1': (1.45+0j), 'LIM2': (1.45+0j), 'CO3': (1.5+0j), 'Na': (1.5+0j), \n",
    "    'Ca': (1.5+0j), 'OIN': (1.55+0.006j), 'OC': (1.45+0j), 'BC': (1.82+0.74j), 'H2O': None}\n",
    "chem2refr_cares = {f'{wvid}/{chem}': chmrfr for wvid in wvid2len \n",
    "    for chem, chmrfr in chem2refr_cares1.items()}\n",
    "chem2refr_cares.update(h2o_refrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_fam = {\n",
    "    ############################ The BlueWaters Chi Sampling Simulation ###########################\n",
    "\n",
    "    ##### Variant I: Full Chemicals and Diameter Range ##### \n",
    "    # The number of time-steps in the simulation\n",
    "    '01_bwchi/n_t': 25,\n",
    "    # The simulation grid size\n",
    "    '01_bwchi/n_grid': (1000, 1, 1),\n",
    "    # The input data's relative directory\n",
    "    '01_bwchi/inp/data_tree': '01_bwchisamp',\n",
    "    # The function for obtaining the input `nc_path` and `snridx_nc`\n",
    "    '01_bwchi/inp/nc_pathfn': get_bwncpath,\n",
    "    # The relative path of the output\n",
    "    '01_bwchi/out/nc_tree': '02_masshist/02_bwchisamp',\n",
    "    # The maximum number of netCDF open files at a time\n",
    "    '01_bwchi/n_maxfp': 1,\n",
    "    # The number of diameter histogram bins\n",
    "    '01_bwchi/n_bins': 20,\n",
    "    # The lower range of the diamter histogram\n",
    "    '01_bwchi/diam_low': 1e-9,\n",
    "    # The higher range of the diamter histogram\n",
    "    '01_bwchi/diam_high': 1e-4,\n",
    "    # The chemical species to keep\n",
    "    '01_bwchi/chem_species': 'all',\n",
    "    # The mapping of chemical species (str) to physical density values (float, kg/m^3)\n",
    "    '01_bwchi/chem2rho': chem2rho_bwchi,\n",
    "    # The mapping of chemical species (str) to physical kappa values (float) for CCN calculaitons\n",
    "    '01_bwchi/chem2kappa': chem2kappa_bwchi,\n",
    "    # The mapping of chemical species (str) to refractive index values (complex) for optical calculations\n",
    "    '01_bwchi/chem2refr': chem2refr_bwchi,\n",
    "    # The mapping of wave length id (str) to wave length\n",
    "    '01_bwchi/wvid2len': wvid2len,\n",
    "\n",
    "    # The output file subtitle\n",
    "    '01_bwchi/subtitle': dedent('''\n",
    "        This file contains the chemical mass histograms from the\n",
    "        PartMC run on the Bluewaters with the chi sampling. All \n",
    "        chemical species and the full range of diameters were \n",
    "        included in this data.'''),\n",
    "\n",
    "    ##### Variant II: Reduced Chemicals and Diameter Range ####\n",
    "    # The number of time-steps in the simulation\n",
    "    '02_bwchi/n_t': 25,\n",
    "    # The simulation grid size\n",
    "    '02_bwchi/n_grid': (1000, 1, 1),\n",
    "    # The input data's relative directory\n",
    "    '02_bwchi/inp/data_tree': '01_bwchisamp',\n",
    "    # The function for obtaining the input `nc_path` and `snridx_nc`\n",
    "    '02_bwchi/inp/nc_pathfn': get_bwncpath,\n",
    "    # The relative path of the output\n",
    "    '02_bwchi/out/nc_tree': '02_masshist/03_bwchisamp',\n",
    "    # The maximum number of netCDF open files at a time\n",
    "    '02_bwchi/n_maxfp': 1,\n",
    "    # The number of diameter histogram bins\n",
    "    '02_bwchi/n_bins': 19,\n",
    "    # The lower range of the diamter histogram\n",
    "    '02_bwchi/diam_low': (10 ** (-8.75)),\n",
    "    # The higher range of the diamter histogram\n",
    "    '02_bwchi/diam_high': 1e-4,\n",
    "    # The chemical species to keep\n",
    "    '02_bwchi/chem_species': 'SO4,NO3,Cl,NH4,ARO1,ARO2,ALK1,OLE1,API1,Na,OIN,OC,BC,MOC,H2O',\n",
    "    # The mapping of chemical species (str) to physical density values (float, kg/m^3)\n",
    "    '02_bwchi/chem2rho': chem2rho_bwchi,\n",
    "    # The mapping of chemical species (str) to physical kappa values (float) for CCN calculaitons\n",
    "    '02_bwchi/chem2kappa': chem2kappa_bwchi,\n",
    "    # The mapping of chemical species (str) to refractive index values (complex) for optical calculations\n",
    "    '02_bwchi/chem2refr': chem2refr_bwchi,\n",
    "    # The mapping of wave length id (str) to wave length\n",
    "    '02_bwchi/wvid2len': wvid2len,\n",
    "\n",
    "    # The output file subtitle\n",
    "    '02_bwchi/subtitle': dedent('''\n",
    "        This file contains the chemical mass histograms from the\n",
    "        PartMC run on the Bluewaters with the chi sampling. A reduced \n",
    "        subset of chemical species and range of diameters were \n",
    "        included in this data.'''),\n",
    "\n",
    "    #################################### The CARES Simulation ####################################\n",
    "    \n",
    "    ##### Variant I: Full Chemicals and Diameter Range ##### \n",
    "    # The number of time-steps in the simulation\n",
    "    '01_cares/n_t': 9,\n",
    "    # The simulation grid size\n",
    "    '01_cares/n_grid': (169, 159, 39),\n",
    "    # The input data's relative directory\n",
    "    '01_cares/inp/data_tree': '03_caressamp',\n",
    "    # The function for obtaining the input `nc_path` and `snridx_nc`\n",
    "    '01_cares/inp/nc_pathfn': get_caresncpath,\n",
    "    # The relative path of the output\n",
    "    '01_cares/out/nc_tree': '02_masshist/04_caressamp',\n",
    "    # The maximum number of netCDF open files at a time\n",
    "    '01_cares/n_maxfp': 10,\n",
    "    # The number of diameter histogram bins\n",
    "    '01_cares/n_bins': 20,\n",
    "    # The lower range of the diamter histogram\n",
    "    '01_cares/diam_low': 1e-9,\n",
    "    # The higher range of the diamter histogram\n",
    "    '01_cares/diam_high': 1e-4,\n",
    "    # The chemical species to keep\n",
    "    '01_cares/chem_species': 'all',\n",
    "    # The mapping of chemical species (str) to physical density values (float, kg/m^3)\n",
    "    '01_cares/chem2rho': chem2rho_cares,\n",
    "    # The mapping of chemical species (str) to physical kappa values (float) for CCN calculaitons\n",
    "    '01_cares/chem2kappa': chem2kappa_cares,\n",
    "    # The mapping of chemical species (str) to refractive index values (complex) for optical calculations\n",
    "    '01_cares/chem2refr': chem2refr_cares,\n",
    "    # The mapping of wave length id (str) to wave length\n",
    "    '01_cares/wvid2len': wvid2len,\n",
    "\n",
    "    # The output file subtitle\n",
    "    '01_cares/subtitle': dedent('''\n",
    "        This file contains the chemical mass histograms from the\n",
    "        PartMC run on the CARES dataset. All chemical species and \n",
    "        the full range of diameters were included in this data.'''),\n",
    "\n",
    "    ##### Variant II: Reduced Chemicals and Diameter Range ####\n",
    "    # The number of time-steps in the simulation\n",
    "    '02_cares/n_t': 9,\n",
    "    # The simulation grid size\n",
    "    '02_cares/n_grid': (169, 159, 39),\n",
    "    # The input data's relative directory\n",
    "    '02_cares/inp/data_tree': '03_caressamp',\n",
    "    # The function for obtaining the input `nc_path` and `snridx_nc`\n",
    "    '02_cares/inp/nc_pathfn': get_caresncpath,\n",
    "    # The relative path of the output\n",
    "    '02_cares/out/nc_tree': '02_masshist/05_caressamp',\n",
    "    # The maximum number of netCDF open files at a time\n",
    "    '02_cares/n_maxfp': 10,\n",
    "    # The number of diameter histogram bins\n",
    "    '02_cares/n_bins': 14,\n",
    "    # The lower range of the diamter histogram\n",
    "    '02_cares/diam_low': (10 ** (-8.25)),\n",
    "    # The higher range of the diamter histogram\n",
    "    '02_cares/diam_high': (10 ** (-4.75)),\n",
    "    # The chemical species to keep\n",
    "    '02_cares/chem_species': 'SO4,Cl,NH4,API1,Na,OC,BC',\n",
    "    # The mapping of chemical species (str) to physical density values (float, kg/m^3)\n",
    "    '02_cares/chem2rho': chem2rho_cares,\n",
    "    # The mapping of chemical species (str) to physical kappa values (float) for CCN calculaitons\n",
    "    '02_cares/chem2kappa': chem2kappa_cares,\n",
    "    # The mapping of chemical species (str) to refractive index values (complex) for optical calculations\n",
    "    '02_cares/chem2refr': chem2refr_cares,\n",
    "    # The mapping of wave length id (str) to wave length\n",
    "    '02_cares/wvid2len': wvid2len,\n",
    "\n",
    "    # The output file subtitle\n",
    "    '02_cares/subtitle': dedent('''\n",
    "        This file contains the chemical mass histograms from the\n",
    "        PartMC run on the CARES dataset. A reduced subset of chemical \n",
    "        species and range of diameters were included in this data.'''),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db087051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fam_data, need_work = args_datafamily, False\n",
    "\n",
    "if my_rank is not None:\n",
    "    # The number of time-steps in the simulation\n",
    "    n_t_all = info_fam[f'{fam_data}/n_t']\n",
    "\n",
    "    # The simulation grid size\n",
    "    n_grid = info_fam[f'{fam_data}/n_grid']\n",
    "\n",
    "    # The input data's relative directory\n",
    "    data_tree = info_fam[f'{fam_data}/inp/data_tree']\n",
    "\n",
    "    # The function for obtaining the input `nc_path` and `snridx_nc`\n",
    "    nc_pathfninp = info_fam[f'{fam_data}/inp/nc_pathfn']\n",
    "\n",
    "    # The relative path of the output\n",
    "    nc_treeout = info_fam[f'{fam_data}/out/nc_tree']\n",
    "\n",
    "    # The maximum number of netCDF open files at a time\n",
    "    n_maxfp = info_fam[f'{fam_data}/n_maxfp']\n",
    "\n",
    "    # The number of diameter histogram bins\n",
    "    n_bins = info_fam[f'{fam_data}/n_bins']\n",
    "\n",
    "    # The lower end of the diamter histogram\n",
    "    diam_low = info_fam[f'{fam_data}/diam_low']\n",
    "\n",
    "    # The higher end of the diamter histogram\n",
    "    diam_high = info_fam[f'{fam_data}/diam_high']\n",
    "\n",
    "    # The chemical species to keep\n",
    "    chem_species_keep = info_fam[f'{fam_data}/chem_species']\n",
    "\n",
    "    # The mapping of chemical species (str) to physical density values (float, kg/m^3)\n",
    "    chem2rho = info_fam[f'{fam_data}/chem2rho']\n",
    "\n",
    "    # The mapping of chemical species (str) to physical kappa values (float) for CCN calculaitons\n",
    "    chem2kappa = info_fam[f'{fam_data}/chem2kappa']\n",
    "\n",
    "    # The mapping of chemical species (str) to refractive index values (complex) for optical calculations\n",
    "    chem2refr = info_fam[f'{fam_data}/chem2refr']\n",
    "\n",
    "    # The mapping of wave length id (str) to wave length\n",
    "    wvid2len = info_fam[f'{fam_data}/wvid2len']\n",
    "\n",
    "    # The output file subtitle\n",
    "    subtitle = info_fam[f'{fam_data}/subtitle']\n",
    "\n",
    "    out_tree = '/'.join(nc_treeout.split('/')[:-1])\n",
    "    nc_pathout = f'{out_datadir}/{nc_treeout}_{my_rank:02d}.nc'\n",
    "\n",
    "    need_work = not(args_belazy and exists(nc_pathout))\n",
    "\n",
    "if (my_rank is not None) and need_work:\n",
    "    # Adjusting for dry runs!\n",
    "    if args_dryrun:\n",
    "        n_grid = tuple(min(aa, bb) for aa, bb in zip(n_grid, (5, 3, 4)))\n",
    "\n",
    "    # Creating the output directory early on, so that any issues will be raised before the computations.\n",
    "    outdir = f'{out_datadir}/{out_tree}'\n",
    "    if not exists(outdir):\n",
    "        os.makedirs(f'{out_datalfsdir}/{out_tree}', exist_ok=True)\n",
    "        os.symlink(f'{out_datalfsdir}/{out_tree}', f'{out_datadir}/{out_tree}')\n",
    "        assert exists(outdir)\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # The logarithmic base\n",
    "    diam_logbase = np.log(10)\n",
    "\n",
    "    # The grid size values in each x-, y-, and z-direction\n",
    "    n_grid_x, n_grid_y, n_grid_z = n_grid\n",
    "    # Defining the subset of scenario and time indecis to loop over\n",
    "    snr_idxs = list(range(n_grid_x * n_grid_y * n_grid_z))\n",
    "    t_idxs = list(range(n_t_all))\n",
    "\n",
    "    my_snridxsnp = np.array_split(snr_idxs, n_workers)[my_rank]\n",
    "    my_snridxs = my_snridxsnp.tolist()\n",
    "    my_snridxsset = set(my_snridxs)\n",
    "    n_waveref = len(wvid2len)\n",
    "\n",
    "    n_snr, n_mysnr, n_t = len(snr_idxs), len(my_snridxs), len(t_idxs)\n",
    "    n_mysamp = n_mysnr * n_t\n",
    "\n",
    "    assert len(my_snridxs) > 0, f'n_workers={n_workers} too big for n_snr={n_snr}'\n",
    "\n",
    "    # The file pointer cache\n",
    "    nc_path2fp = odict()\n",
    "    assert n_maxfp > 0\n",
    "\n",
    "    # Compiling the list of targets for my rank\n",
    "    prod_itrtr = product(range(n_grid_x), range(n_grid_y), range(n_grid_z))\n",
    "    my_targets = [(scnr_idx, i_x, i_y, i_z)\n",
    "        for scnr_idx, (i_x, i_y, i_z) in enumerate(prod_itrtr)\n",
    "        if scnr_idx in my_snridxsset]\n",
    "\n",
    "    mytqdm = tqdm if (my_rank == 0) else lambda aa: aa\n",
    "    chem_species_str, n_chem, keydims = None, None, None\n",
    "    hist_datalst = defaultdict(list)\n",
    "    for scnr_idx, i_x, i_y, i_z in mytqdm(my_targets):\n",
    "        if not use_tqdm:\n",
    "            print('.', end='', flush=True)\n",
    "        for t_idx in t_idxs:\n",
    "            nc_path, snridx_nc = nc_pathfninp(data_dir=data_dir, \n",
    "                data_tree=data_tree, i_grid=(i_x, i_y, i_z), n_grid=n_grid, \n",
    "                scnr_idx=scnr_idx, t_idx=t_idx)\n",
    "            \n",
    "            # Looking up the file pointer cache\n",
    "            if nc_path in nc_path2fp:\n",
    "                nc_fp = nc_path2fp[nc_path]\n",
    "            else:\n",
    "                # Making sure we have at most `n_maxfp-1` open file \n",
    "                # pointers before we open a new one.\n",
    "                while len(nc_path2fp) >= n_maxfp:\n",
    "                    ncpath_old = next(iter(nc_path2fp))\n",
    "                    ncfp_old = nc_path2fp.pop(ncpath_old)\n",
    "                    ncfp_old.close()\n",
    "                    \n",
    "                nc_fp = Dataset(nc_path, \"r\")\n",
    "                nc_path2fp[nc_path] = nc_fp\n",
    "\n",
    "            hist_data = get_histdata(nc_fp, nc_path, snridx_nc, n_bins, diam_low, \n",
    "                diam_high, diam_logbase, chem_species_keep, lib='numpy')\n",
    "\n",
    "            chemspcsstrthis = hist_data.pop('chem_species_str')\n",
    "            chem_species_str = chemspcsstrthis if chem_species_str is None else chem_species_str\n",
    "            assert chem_species_str == chemspcsstrthis, dedent(f'''\n",
    "                    {chem_species_str} != {chemspcsstrthis}''')\n",
    "\n",
    "            if keydims is None:\n",
    "                keydims = {key: val.shape for key, val in hist_data.items()}\n",
    "\n",
    "            assert set(hist_data) == set(keydims), dedent(f''''\n",
    "                New unusal keys are being introduced later:\n",
    "                    usual keys: {keydims.keys()}\n",
    "                    new keys: {hist_data.keys()}''')\n",
    "\n",
    "            for key, val in hist_data.items():\n",
    "                assert val.shape == keydims[key], dedent(f''''\n",
    "                    {key} has a different shape than usual:\n",
    "                        usual shape: {keydims[key]}\n",
    "                        new shape: {val.shape}''')\n",
    "\n",
    "                hist_datalst[key].append(val)\n",
    "    \n",
    "    chem_species_lst = chem_species_str.split(',')\n",
    "    \n",
    "    # The chemical density values in kg / m^3.\n",
    "    rho_chmnp = np.array([chem2rho[chem] for chem in chem_species_lst], dtype=np.float64)\n",
    "    \n",
    "    # The chemical kappa values for CCN calculations\n",
    "    kappa_chmnp = np.array([chem2kappa[chem] for chem in chem_species_lst], dtype=np.float64)\n",
    "    \n",
    "    # The chemical refraction index values for optical property calculations\n",
    "    wave_idssrtd = [wvid for wvid, wvlen in sorted(wvid2len.items(), key=lambda pair: pair[1])]\n",
    "    refr_wvchmrefnp = np.array([\n",
    "        [chem2refr[f'{wvid}/{chem}'] for chem in chem_species_lst] \n",
    "        for wvid in wave_idssrtd]).astype(np.complex128)\n",
    "    len_wvrefnp = np.array([wvid2len[wvid] for wvid in wave_idssrtd])\n",
    "    \n",
    "    # Closing any remaining open file pointers\n",
    "    for ncpath_old in list(nc_path2fp):\n",
    "        ncfp_old = nc_path2fp.pop(ncpath_old)\n",
    "        ncfp_old.close()\n",
    "\n",
    "    hist_data = dict()\n",
    "    for key, val_lst in hist_datalst.items():\n",
    "        myval1 = np.stack(val_lst, axis=0)\n",
    "        assert myval1.shape == (n_mysnr * n_t, *keydims[key])\n",
    "        myval2 = myval1.reshape(n_mysnr, n_t, *keydims[key])\n",
    "        assert myval2.shape == (n_mysnr, n_t, *keydims[key])\n",
    "        hist_data[key] = myval2\n",
    "        \n",
    "    if my_rank == 0:\n",
    "        print(f'\\nFinished collecting the data from disk in {time.perf_counter()-start_time:.2f}!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f91cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing the histogram data to disk\n",
    "if (my_rank is not None) and need_work:\n",
    "    # Extracting the histogram data\n",
    "    n_chem = hist_data['m_chmprthst'].shape[-2]\n",
    "    \n",
    "    n_prthst = hist_data.pop('n_prthst')\n",
    "    assert n_prthst.shape == (n_mysnr, n_t, n_bins)\n",
    "    assert n_prthst.dtype == np.int64, n_prthst.dtype\n",
    "    m_prthst = hist_data.pop('m_prthst')\n",
    "    assert m_prthst.shape == (n_mysnr, n_t, n_bins)\n",
    "    assert m_prthst.dtype == np.float64, m_prthst.dtype\n",
    "    m_chmprthst = hist_data.pop('m_chmprthst')\n",
    "    assert m_chmprthst.shape == (n_mysnr, n_t, n_chem, n_bins), dedent(f'''\n",
    "        {m_chmprthst.shape} != {(n_mysnr, n_t, n_chem, n_bins)}''')\n",
    "    assert m_chmprthst.dtype == np.float64, m_chmprthst.dtype\n",
    "\n",
    "    # Making sure no data item is left over\n",
    "    assert len(hist_data) == 0, f'{hist_data}'\n",
    "\n",
    "    ncfile = Dataset(nc_pathout, mode='w', format='NETCDF4')\n",
    "    # The number of entire scenarios\n",
    "    nsnr_dim = ncfile.createDimension('n_snr', n_mysnr)\n",
    "    # The number of entire scenarios\n",
    "    nsnr_dim = ncfile.createDimension('n_snr_all', n_snr)\n",
    "    # The number of time steps in each scenario\n",
    "    nt_dim = ncfile.createDimension('n_t', n_t)\n",
    "    # The number of entire samples\n",
    "    nsamp_dim = ncfile.createDimension('n_samp', n_mysamp)\n",
    "    # The number of diameter histogram bins\n",
    "    kbins_dim = ncfile.createDimension('n_bins', n_bins)\n",
    "    # The number of chemical specices\n",
    "    nchem_dim = ncfile.createDimension('n_chem', n_chem)\n",
    "    # The number of chemical specices\n",
    "    nwave_dim = ncfile.createDimension('n_wave', n_waveref)\n",
    "    # The x-axis grid size of the simulation\n",
    "    ngridx_dim = ncfile.createDimension('n_grid_x', n_grid_x)\n",
    "    # The y-axis grid size of the simulation\n",
    "    ngridy_dim = ncfile.createDimension('n_grid_y', n_grid_y)\n",
    "    # The z-axis grid size of the simulation\n",
    "    ngridz_dim = ncfile.createDimension('n_grid_z', n_grid_z)\n",
    "    # unit dimension\n",
    "    one_dim = ncfile.createDimension('one', 1)\n",
    "\n",
    "    # Keeping a record of which dimensions belonged to my rank\n",
    "    i_targs = np.array(my_targets).astype(np.int64)\n",
    "    assert i_targs.shape == (n_mysnr, 4)\n",
    "    \n",
    "    i_snr, i_x, i_y, i_z = i_targs.T\n",
    "    assert i_snr.shape == (n_mysnr,)\n",
    "    assert i_x.shape == (n_mysnr,)\n",
    "    assert i_y.shape == (n_mysnr,)\n",
    "    assert i_z.shape == (n_mysnr,)\n",
    "\n",
    "    # Adding the file title/subtitle\n",
    "    ncfile.title = 'The chemical mass histograms'\n",
    "    ncfile.subtitle = subtitle\n",
    "\n",
    "    # The range of the diamter histogram\n",
    "    dlow_nc = ncfile.createVariable('diam_low', np.float64, ('one',))\n",
    "    dlow_nc.units = 'm'\n",
    "    dlow_nc.long_name = 'diameter_lower_bound'\n",
    "\n",
    "    dhigh_nc = ncfile.createVariable('diam_high', np.float64, ('one',))\n",
    "    dhigh_nc.units = 'm'\n",
    "    dhigh_nc.long_name = 'diameter_upper_bound'\n",
    "\n",
    "    # The logarithmic base\n",
    "    logbase_nc = ncfile.createVariable('diam_logbase', np.float64, ('one',))\n",
    "    logbase_nc.units = 'none'\n",
    "    logbase_nc.long_name = 'diameter_log_base'\n",
    "\n",
    "    # The chemical species names\n",
    "    chmspcs_nc = ncfile.createVariable('chem_species', np.int64, ('n_chem',))\n",
    "    chmspcs_nc.units = 'none'\n",
    "    chmspcs_nc.names = chem_species_str\n",
    "    chmspcs_nc.long_name = chem_species_str\n",
    "\n",
    "    # The chemical density values in kg / m^3.\n",
    "    chmrho_nc = ncfile.createVariable('chem_rho', np.float64, ('n_chem',))\n",
    "    chmrho_nc.units = 'kg/m^3'\n",
    "    chmrho_nc.long_name = 'chem_density'\n",
    "\n",
    "    # The chemical kappa values for CCN calculations\n",
    "    chmkappa_nc = ncfile.createVariable('chem_kappa', np.float64, ('n_chem',))\n",
    "    chmkappa_nc.units = 'none'\n",
    "    chmkappa_nc.long_name = 'chem_kappa'\n",
    "\n",
    "    # The wave lengths for optical property calculations\n",
    "    lenwv_nc = ncfile.createVariable('wave_len', np.float64, ('n_wave',))\n",
    "    lenwv_nc.units = 'none'\n",
    "    lenwv_nc.long_name = 'wave_len'\n",
    "\n",
    "    # The real chemical refraction index values for optical property calculations\n",
    "    chmrefrreal_nc = ncfile.createVariable('chem_refr_real', np.float64, ('n_wave', 'n_chem'))\n",
    "    chmrefrreal_nc.units = 'none'\n",
    "    chmrefrreal_nc.long_name = 'chem_refraction_real'\n",
    "\n",
    "    # The imaginary chemical refraction index values for optical property calculations\n",
    "    chmrefrimag_nc = ncfile.createVariable('chem_refr_imag', np.float64, ('n_wave', 'n_chem'))\n",
    "    chmrefrimag_nc.units = 'none'\n",
    "    chmrefrimag_nc.long_name = 'chem_refraction_imag'\n",
    "\n",
    "    # Writing the data to the netCDF file\n",
    "    n_prthst_nc = ncfile.createVariable('n_prthst', np.int64, ('n_samp', 'n_bins'))\n",
    "    n_prthst_nc.units = 'prt/log(m)'\n",
    "    n_prthst_nc.long_name = 'num_particles_histogram'\n",
    "\n",
    "    m_prthst_nc = ncfile.createVariable('m_prthst', np.float64, ('n_samp', 'n_bins'))\n",
    "    m_prthst_nc.units = 'kg/log(m)'\n",
    "    m_prthst_nc.long_name = 'mass_particles_histogram_net'\n",
    "\n",
    "    m_chmprthst_nc = ncfile.createVariable('m_chmprthst', np.float64, ('n_samp', 'n_chem', 'n_bins'))\n",
    "    m_chmprthst_nc.units = 'kg/log(m)'\n",
    "    m_chmprthst_nc.long_name = 'mass_particles_histogram_speciated'\n",
    "\n",
    "    i_snr_nc = ncfile.createVariable('i_snr', np.int64, ('n_snr',))\n",
    "    i_snr_nc.units = 'one'\n",
    "    i_snr_nc.long_name = 'included_snr_idxs_in_my_rank'\n",
    "\n",
    "    i_x_nc = ncfile.createVariable('i_x', np.int64, ('n_snr',))\n",
    "    i_x_nc.units = 'one'\n",
    "    i_x_nc.long_name = 'included_x_grid_idxs_in_my_rank'\n",
    "\n",
    "    i_y_nc = ncfile.createVariable('i_y', np.int64, ('n_snr',))\n",
    "    i_y_nc.units = 'one'\n",
    "    i_y_nc.long_name = 'included_y_grid_idxs_in_my_rank'\n",
    "\n",
    "    i_z_nc = ncfile.createVariable('i_z', np.int64, ('n_snr',))\n",
    "    i_z_nc.units = 'one'\n",
    "    i_z_nc.long_name = 'included_z_grid_idxs_in_my_rank'\n",
    "\n",
    "    dlow_nc[:], dhigh_nc[:], logbase_nc[:] = diam_low, diam_high, diam_logbase\n",
    "    chmspcs_nc[:] = np.arange(n_chem)\n",
    "    n_prthst_nc[:] = n_prthst.reshape(n_mysamp, n_bins)\n",
    "    m_prthst_nc[:] = m_prthst.reshape(n_mysamp, n_bins)\n",
    "    m_chmprthst_nc[:] = m_chmprthst.reshape(n_mysamp, n_chem, n_bins)\n",
    "    i_snr_nc[:], i_x_nc[:], i_y_nc[:], i_z_nc[:] = i_snr, i_x, i_y, i_z\n",
    "    chmrho_nc[:], chmkappa_nc[:] = rho_chmnp, kappa_chmnp\n",
    "    chmrefrreal_nc[:], chmrefrimag_nc[:] = refr_wvchmrefnp.real, refr_wvchmrefnp.imag\n",
    "    lenwv_nc[:] = len_wvrefnp\n",
    "\n",
    "    # Closing the netCDF file\n",
    "    ncfile.close()\n",
    "    if my_rank == 0:\n",
    "        print('Done!', flush=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "837309a3",
   "metadata": {
    "tags": [
     "active-py"
    ]
   },
   "source": [
    "if args_dryrun and (my_rank == 0):\n",
    "    print(f'>> [dry-run] Cleaning up {temp_datadir.name}')\n",
    "    temp_datadir.cleanup()\n",
    "    print(f'>> [dry-run] Cleaning up {temp_datalfsdir.name}')\n",
    "    temp_datalfsdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a297e5",
   "metadata": {},
   "source": [
    "# Compiling All Data into a Single netCDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cddc83",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "fam_data = None\n",
    "\n",
    "# NetCDF Dimension Compilation Rules\n",
    "dim_cmplrules = {'n_snr': 'sum', 'n_t': 'same', 'n_samp': 'sum', 'n_snr_all': 'same',\n",
    "    'n_bins': 'same', 'n_chem': 'same', 'n_wave': 'same', 'n_grid_x': 'same', \n",
    "    'n_grid_y': 'same', 'n_grid_z': 'same', 'one': 'same'}\n",
    "\n",
    "# NetCDF Variable Compilation Rules\n",
    "var_cmplrules = {\n",
    "    'diam_low': ('same', np.float64), \n",
    "    'diam_high': ('same', np.float64), \n",
    "    'diam_logbase': ('same', np.float64), \n",
    "    'chem_species': ('same', np.int64), \n",
    "    'chem_rho': ('same', np.float64), \n",
    "    'chem_kappa': ('same', np.float64), \n",
    "    'chem_refr_real': ('same', np.float64), \n",
    "    'chem_refr_imag': ('same', np.float64), \n",
    "    'wave_len': ('same', np.float64), \n",
    "    'n_prthst': ('cat', np.int64), \n",
    "    'm_prthst': ('cat', np.float64), \n",
    "    'm_chmprthst': ('cat', np.float64), \n",
    "    'i_snr': ('cat', np.int64), \n",
    "    'i_x': ('cat', np.int64), \n",
    "    'i_y': ('cat', np.int64), \n",
    "    'i_z': ('cat', np.int64)}\n",
    "\n",
    "if fam_data is not None:\n",
    "    ################################ Phase I #################################\n",
    "    ############## Reading all the data from all the rank files ##############\n",
    "\n",
    "    # The relative path of the output\n",
    "    nc_treeout = info_fam[f'{fam_data}/out/nc_tree']\n",
    "\n",
    "    rank2ncfp = dict()\n",
    "    out_tree = '/'.join(nc_treeout.split('/')[:-1])\n",
    "\n",
    "    rank_ncpaths = glob.glob(f'{out_datadir}/{nc_treeout}_*.nc')\n",
    "    rank_strs_ = [ncpth.split('_')[-1].split('.')[0] for ncpth in rank_ncpaths]\n",
    "    ranks_lst = [int(rnkstr) for rnkstr in rank_strs_ if rnkstr.isdigit()]\n",
    "    ranks_lst = sorted(ranks_lst)\n",
    "    assert ranks_lst == list(range(len(ranks_lst)))\n",
    "\n",
    "    for rank in ranks_lst:\n",
    "        nc_pathrank = f'{out_datadir}/{nc_treeout}_{rank:02d}.nc'\n",
    "        nc_fp = Dataset(nc_pathrank, mode='r', format='NETCDF4')\n",
    "        rank2ncfp[rank] = nc_fp\n",
    "\n",
    "    # Compiling NetCDF Dimensions\n",
    "    dims_cmpld = dict()\n",
    "    for rank, nc_fp in rank2ncfp.items():\n",
    "        # all keys must be accounted for\n",
    "        rank_dims = {key: val.size for key, val in nc_fp.dimensions.items()}\n",
    "        assert set(rank_dims) == set(dim_cmplrules), dedent(f'''\n",
    "            {rank_dims.keys()} != {dim_cmplrules.keys()}''')\n",
    "        \n",
    "        # summing or same-proofing each dimensions\n",
    "        for key, cmpl_rule in dim_cmplrules.items():\n",
    "            dim = rank_dims[key]\n",
    "            if cmpl_rule == 'sum':\n",
    "                dims_cmpld.setdefault(key, 0)\n",
    "                dims_cmpld[key] += dim\n",
    "            elif cmpl_rule == 'same':\n",
    "                dims_cmpld.setdefault(key, dim)\n",
    "                assert dims_cmpld[key] == dim\n",
    "            else:\n",
    "                raise ValueError(f'undefined cmpl_rule = {cmpl_rule}')\n",
    "\n",
    "    # Compiling NetCDF Attributes\n",
    "    attrs_cmpld = dict(vars(rank2ncfp[ranks_lst[0]]))\n",
    "    assert all(dict(vars(nc_fp)) == attrs_cmpld \n",
    "        for rank, nc_fp in rank2ncfp.items())\n",
    "\n",
    "    # Compiling NetCDF Variables\n",
    "    vars_catlst = defaultdict(list)\n",
    "    vars_cmpld = dict()\n",
    "    varattrs_cmpld = dict()\n",
    "    vardimnames_cmpld = dict()\n",
    "\n",
    "    for rank, nc_fp in rank2ncfp.items():\n",
    "        # Making sure the variables all have defined rules\n",
    "        assert set(nc_fp.variables) == set(var_cmplrules), dedent(f'''\n",
    "            {nc_fp.variables.keys()} != {var_cmplrules.keys()}''')\n",
    "            \n",
    "        for key, (cmpl_rule, key_dtype) in var_cmplrules.items():\n",
    "            rank_varbl = nc_fp.variables[key]\n",
    "\n",
    "            # Making sure the key has the anticipated dtype\n",
    "            assert rank_varbl.dtype == key_dtype, f'{rank_varbl.dtype} != {key_dtype}'\n",
    "\n",
    "            # appending or same-proofing each value\n",
    "            if cmpl_rule == 'same':\n",
    "                if key not in vars_cmpld:\n",
    "                    vars_cmpld[key] = rank_varbl[:]\n",
    "                assert np.all(vars_cmpld[key] == rank_varbl)\n",
    "            elif cmpl_rule == 'cat':\n",
    "                vars_catlst[key].append(rank_varbl[:])\n",
    "            else:\n",
    "                raise ValueError(f'undefined cmpl_rule = {cmpl_rule}')\n",
    "\n",
    "            # The variable attributes should be identical\n",
    "            if key not in varattrs_cmpld:\n",
    "                varattrs_cmpld[key] = dict(vars(rank_varbl))\n",
    "            assert varattrs_cmpld[key] == dict(vars(rank_varbl))\n",
    "\n",
    "            # The variable dimension names should be identical\n",
    "            if key not in vardimnames_cmpld:\n",
    "                vardimnames_cmpld[key] = rank_varbl.dimensions\n",
    "            assert vardimnames_cmpld[key] == rank_varbl.dimensions\n",
    "\n",
    "    # Concatenating all the values\n",
    "    for key, arr_list in vars_catlst.items():\n",
    "        vars_cmpld[key] = np.concatenate(arr_list, axis=0)\n",
    "\n",
    "    # Closing all the open file pointers\n",
    "    for rank, nc_fp in rank2ncfp.items():\n",
    "        nc_fp.close()\n",
    "\n",
    "    ################################ Phase II ################################\n",
    "    ######################## Writing the Compiled Data #######################\n",
    "\n",
    "    nc_pathout = f'{out_datadir}/{nc_treeout}.nc'\n",
    "    nc_fpout = Dataset(nc_pathout, mode='w', format='NETCDF4')\n",
    "\n",
    "    # Writing the dimensions\n",
    "    for dim_name, dim_val in dims_cmpld.items():\n",
    "        nc_fpout.createDimension(dim_name, dim_val)\n",
    "\n",
    "    # Writing the attributes\n",
    "    for attr_name, attr_val in attrs_cmpld.items():\n",
    "        setattr(nc_fpout, attr_name, attr_val)\n",
    "\n",
    "    # Writing the variables\n",
    "    for key, varbl in vars_cmpld.items():\n",
    "        key_cmplrule, key_dtype = var_cmplrules[key]\n",
    "        key_dimnames = vardimnames_cmpld[key]\n",
    "        nc_var = nc_fpout.createVariable(key, key_dtype, key_dimnames)\n",
    "        for attr_name, attr_val in varattrs_cmpld[key].items():\n",
    "            setattr(nc_var, attr_name, attr_val)\n",
    "        nc_var[:] = varbl\n",
    "\n",
    "    # Closing the netCDF file\n",
    "    nc_fpout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee51c7",
   "metadata": {},
   "source": [
    "# Loading the Histogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d84c4",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "fam_data, grid_ssfrqs = '02_bwchi', None\n",
    "fam_data, grid_ssfrqs = '02_cares', (10, 10, 10, 1)\n",
    "\n",
    "nc_treeout = info_fam[f'{fam_data}/out/nc_tree']\n",
    "data_path = f'{data_dir}/{nc_treeout}.nc'\n",
    "assert data_path.endswith('.nc')\n",
    "n_grid_x, n_grid_y, n_grid_z = info_fam[f'{fam_data}/n_grid']\n",
    "\n",
    "with Dataset(data_path, \"r\") as fp:\n",
    "    ################# The Array Dimensions #################\n",
    "    # The number of scenarios\n",
    "    n_snrall = fp.dimensions['n_snr'].size\n",
    "    # The number of time steps in each scenario\n",
    "    n_t = fp.dimensions['n_t'].size\n",
    "    # The number of diameter histogram bins\n",
    "    n_bins = fp.dimensions['n_bins'].size\n",
    "    # The number of chemical specices\n",
    "    n_chem = fp.dimensions['n_chem'].size\n",
    "    # The number of wave lengths\n",
    "    n_wave = fp.dimensions['n_wave'].size\n",
    "\n",
    "    # Applying the sub-sampling\n",
    "    if grid_ssfrqs is not None:\n",
    "        x_ssfrq, y_ssfrq, z_ssfrq, t_ssfrq = grid_ssfrqs\n",
    "        assert n_snrall == (n_grid_x * n_grid_y * n_grid_z)\n",
    "        i_snrs1 = np.arange(n_snrall * n_t).reshape(n_grid_x, n_grid_y, n_grid_z, n_t)\n",
    "        assert i_snrs1.shape == (n_grid_x, n_grid_y, n_grid_z, n_t)\n",
    "        i_snrs2 = i_snrs1[::x_ssfrq, ::y_ssfrq, ::z_ssfrq, ::t_ssfrq]\n",
    "        n_samp = i_snrs2.size\n",
    "        n_snr, n_t = math.prod(i_snrs2.shape[:-1]), i_snrs2.shape[-1]\n",
    "        i_snrs = i_snrs2.ravel()\n",
    "        assert i_snrs.shape == (n_samp,)\n",
    "    else:\n",
    "        n_snr, n_samp = n_snrall, n_snrall * n_t\n",
    "        i_snrs = slice(None, None, None)\n",
    "\n",
    "    #################### The Data Arrays ####################\n",
    "    # The number of particles within each diameter bin\n",
    "    n_prthst_ = fp.variables['n_prthst'][i_snrs]\n",
    "    assert n_prthst_.shape == (n_samp, n_bins)\n",
    "    n_prthst = n_prthst_.reshape(n_snr, n_t, n_bins)\n",
    "    assert n_prthst.shape == (n_snr, n_t, n_bins)\n",
    "\n",
    "    # The mass within each diameter bin (the mass histogram)\n",
    "    m_prthst_ = fp.variables['m_prthst'][i_snrs]\n",
    "    assert m_prthst_.shape == (n_samp, n_bins)\n",
    "    m_prthst = m_prthst_.reshape(n_snr, n_t, n_bins)\n",
    "    assert m_prthst.shape == (n_snr, n_t, n_bins)\n",
    "\n",
    "    # The mass of each chemical species within the diameter bins\n",
    "    m_chmprthst_ = fp.variables['m_chmprthst'][i_snrs]\n",
    "    assert m_chmprthst_.shape == (n_samp, n_chem, n_bins)\n",
    "    m_chmprthst = m_chmprthst_.reshape(n_snr, n_t, n_chem, n_bins)\n",
    "    assert m_chmprthst.shape == (n_snr, n_t, n_chem, n_bins)\n",
    "\n",
    "    ####################### Meta-Data #######################\n",
    "    # The Chemical Species\n",
    "    chem_species_str = fp.variables['chem_species'].names\n",
    "\n",
    "    # The chemical density for each species in (kg/m^3)\n",
    "    rho_chm = fp.variables['chem_rho'][:]\n",
    "    assert rho_chm.shape == (n_chem,)\n",
    "    # The kappa of the chemical species.\n",
    "    kappa_chm = fp.variables['chem_kappa'][:]\n",
    "    assert kappa_chm.shape == (n_chem,)\n",
    "    # The real refraction indices of the chemical species at the 550nm wave length.\n",
    "    refr_wvchem_real = fp.variables['chem_refr_real'][:]\n",
    "    assert refr_wvchem_real.shape == (n_wave, n_chem)\n",
    "    # The imaginary refraction indices of the chemical species at the 550nm wave length.\n",
    "    refr_wvchem_imag = fp.variables['chem_refr_imag'][:]\n",
    "    assert refr_wvchem_imag.shape == (n_wave, n_chem)\n",
    "    # The complex refraction indices of the chemical species at the 550nm wave length.\n",
    "    refr_wvchem = refr_wvchem_real + 1j * refr_wvchem_imag\n",
    "    assert refr_wvchem.shape == (n_wave, n_chem)\n",
    "\n",
    "    # The histogram bin lower range of diameters\n",
    "    diam_low = fp.variables['diam_low'][:].item()\n",
    "    # The histogram bin higher range of diameters\n",
    "    diam_high = fp.variables['diam_high'][:].item()\n",
    "    # The diameter log base\n",
    "    diam_logbase = fp.variables['diam_logbase'][:].item()\n",
    "\n",
    "    logdiam_low, logdiam_high = np.log(diam_low) / diam_logbase, np.log(diam_high) / diam_logbase\n",
    "    logdiams = np.linspace(logdiam_low, logdiam_high, n_bins + 1, endpoint=True)\n",
    "    x_histbins = np.exp(logdiams * diam_logbase)\n",
    "    assert x_histbins.shape == (n_bins + 1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc00a78",
   "metadata": {},
   "source": [
    "# Plotting the Mass Stacked Histogram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c058817",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "nrows, ncols = {'02_bwchi': (5, 5), '01_cares': (3, 3), '02_cares': (3, 3)}[fam_data]\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.8*nrows), sharex=True, sharey=True)\n",
    "axes = np.array(axes).reshape(nrows * ncols)\n",
    "\n",
    "# The index of the scenario to show\n",
    "snr_idx = 0\n",
    "# Whether to normalize the values by the diameter bin widhts\n",
    "do_normalize = True\n",
    "# The y-axis mass unit (either 'kg' or 'g')\n",
    "mass_unit = 'g'\n",
    "\n",
    "logdiam_low, logdiam_high = np.log(diam_low) / diam_logbase, np.log(diam_high)/diam_logbase\n",
    "for t_idx in range(nrows * ncols):\n",
    "    m_prthst_t = m_prthst[snr_idx, t_idx]\n",
    "    assert m_prthst_t.shape == (n_bins,)\n",
    "    m_chmprthst_t = m_chmprthst[snr_idx, t_idx].T\n",
    "    assert m_chmprthst_t.shape == (n_bins, n_chem)\n",
    "    \n",
    "    if do_normalize:\n",
    "        bin_width = (logdiam_high - logdiam_low) / n_bins\n",
    "        m_prthst_t = m_prthst_t / bin_width\n",
    "        m_chmprthst_t = m_chmprthst_t / bin_width\n",
    "\n",
    "    m_mul = {'g': 1000, 'kg': 1}[mass_unit]\n",
    "    m_prthst_t = m_prthst_t * m_mul / bin_width\n",
    "    m_chmprthst_t = m_chmprthst_t * m_mul / bin_width\n",
    "\n",
    "    m_chmcs = np.cumsum(m_chmprthst_t, axis=1)\n",
    "    assert m_chmcs.shape == (n_bins, n_chem)\n",
    "\n",
    "    logdiams = np.linspace(logdiam_low, logdiam_high, n_bins, endpoint=False)\n",
    "    bin_width = (logdiam_high - logdiam_low) / n_bins\n",
    "    y_prfxstr = ('(Norm.) ' if do_normalize else '')\n",
    "\n",
    "    ax = axes[t_idx]\n",
    "    i_row, i_col = t_idx // ncols, t_idx % ncols\n",
    "    colors = sns.color_palette('bright', n_chem)\n",
    "    for i_chm in range(n_chem): \n",
    "        ax.bar(logdiams, m_chmprthst_t[:, i_chm], width=bin_width, align='edge',\n",
    "            edgecolor='black', bottom=m_chmcs[:, i_chm-1] if i_chm > 0 else 0, color=colors[i_chm])\n",
    "    ax.set_xlim(logdiam_low, logdiam_high)\n",
    "\n",
    "    ax.set_title(f'Time={t_idx:02d}:00:00')\n",
    "    if i_row == (nrows - 1):\n",
    "        ax.set_xlabel('Diameter')\n",
    "    if i_col == 0:\n",
    "        ax.set_ylabel(f'{y_prfxstr}Species Mass')\n",
    "\n",
    "    engfmtx = EngFormatter(unit='m', sep='')\n",
    "    x_ticks = ax.get_xticks()\n",
    "    x_ticklabels = [engfmtx(np.exp(xtck * diam_logbase)) for xtck in x_ticks]\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_ticklabels)\n",
    "\n",
    "    ax.set_yscale('symlog', linthresh=1e-11)\n",
    "    engfmty = EngFormatter(sep='', unit=mass_unit)\n",
    "    ax.yaxis.set_major_formatter(engfmty)\n",
    "\n",
    "fig.set_tight_layout({\"w_pad\": 0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed9f1b",
   "metadata": {},
   "source": [
    "# Plotting the Mass Pre-Processing Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdc9fc",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib\n",
    "from copy import deepcopy\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "    message=\"divide by zero encountered in log10\")\n",
    "\n",
    "def pp_data(pp_id, eps, exponent):\n",
    "    m_chmprthst1 = np.array(m_chmprthst) + eps\n",
    "    assert m_chmprthst1.shape == (n_snr, n_t, n_chem, n_bins)\n",
    "\n",
    "    if pp_id == 'legacy':\n",
    "        m_chmprthst1b = m_chmprthst1\n",
    "        assert m_chmprthst1b.shape == (n_snr, n_t, n_chem, n_bins)\n",
    "    elif pp_id == 'root':\n",
    "        m_chmprthst1b = np.power(m_chmprthst1, exponent)\n",
    "        assert m_chmprthst1b.shape == (n_snr, n_t, n_chem, n_bins)\n",
    "    else:\n",
    "        raise ValueError(f'undefined pp_id = {pp_id}')\n",
    "\n",
    "    m_chmprthst2 = m_chmprthst1b.reshape(n_snr * n_t, n_chem * n_bins)\n",
    "    assert m_chmprthst2.shape == (n_snr * n_t, n_chem * n_bins)\n",
    "\n",
    "    m_chmprthst3 = (m_chmprthst2**2).sum(axis=-1, keepdims=True) ** 0.5\n",
    "    assert m_chmprthst3.shape == (n_snr * n_t, 1)\n",
    "\n",
    "    m_chmprthst4 = m_chmprthst2 / m_chmprthst3\n",
    "    assert m_chmprthst4.shape == (n_snr * n_t, n_chem * n_bins)\n",
    "\n",
    "    m_chmprthst5 = m_chmprthst4.mean(axis=0)\n",
    "    assert m_chmprthst5.shape == (n_chem * n_bins,)\n",
    "\n",
    "    m_chmprthst6 = m_chmprthst4.std(axis=0)\n",
    "    assert m_chmprthst6.shape == (n_chem * n_bins,)\n",
    "\n",
    "    if pp_id == 'legacy':\n",
    "        m_chmprthst7 = np.log(m_chmprthst3)\n",
    "        assert m_chmprthst7.shape == (n_snr * n_t, 1)\n",
    "    elif pp_id == 'root':\n",
    "        m_chmprthst7 = np.power(m_chmprthst3, exponent)\n",
    "        assert m_chmprthst7.shape == (n_snr * n_t, 1)\n",
    "    else:\n",
    "        raise ValueError(f'undefined pp_id = {pp_id}')\n",
    "\n",
    "    m_chmprthst8 = m_chmprthst7.reshape(n_snr * n_t, 1, 1)\n",
    "    assert m_chmprthst8.shape == (n_snr * n_t, 1, 1)\n",
    "\n",
    "    m_chmprthst9 = m_chmprthst8.mean(axis=0, keepdims=True)[None]\n",
    "    assert m_chmprthst9.shape == (1, 1, 1, 1)\n",
    "\n",
    "    m_chmprthst10 = m_chmprthst8.std(axis=0, keepdims=True)[None]\n",
    "    assert m_chmprthst10.shape == (1, 1, 1, 1)\n",
    "\n",
    "\n",
    "    m_chmprthst11 = m_chmprthst4.reshape(n_snr * n_t, n_chem, n_bins)\n",
    "    assert m_chmprthst11.shape == (n_snr * n_t, n_chem, n_bins)\n",
    "    \n",
    "    if pp_id == 'legacy':\n",
    "        m_chmprthst12 = m_chmprthst11.mean(axis=0, keepdims=True)\n",
    "        assert m_chmprthst12.shape == (1, n_chem, n_bins)\n",
    "\n",
    "        m_chmprthst13 = m_chmprthst11.std(axis=0, keepdims=True)\n",
    "        assert m_chmprthst13.shape == (1, n_chem, n_bins)\n",
    "    elif pp_id == 'root':\n",
    "        m_chmprthst12 = m_chmprthst11.mean(axis=(0, -1), keepdims=True)\n",
    "        assert m_chmprthst12.shape == (1, n_chem, 1)\n",
    "        \n",
    "        m_chmprthst13 = m_chmprthst11.std(axis=(0, -1), keepdims=True)\n",
    "        assert m_chmprthst13.shape == (1, n_chem, 1)\n",
    "    else:\n",
    "        raise ValueError(f'undefined pp_id = {pp_id}')\n",
    "    \n",
    "    m_chmprthst14 = (m_chmprthst11 - m_chmprthst12) / m_chmprthst13\n",
    "    assert m_chmprthst14.shape == (n_snr * n_t, n_chem, n_bins)\n",
    "    \n",
    "    m_chmprthst15 = ((m_chmprthst14**2).mean(axis=0)**0.5).ravel()\n",
    "    assert m_chmprthst15.shape == (n_chem * n_bins,)\n",
    "    \n",
    "    globals().update(**locals())\n",
    "\n",
    "def plot_heatmap(plt_data, x_histbins):\n",
    "    fig, ax = plt.subplots(1, 1, dpi=100, figsize=(6, 6))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.5)\n",
    "\n",
    "    cmap = matplotlib.cm.Reds\n",
    "    cmap.set_bad('white',1.)\n",
    "    im = ax.imshow(plt_data, cmap=cmap)\n",
    "\n",
    "    xticks = np.arange(n_bins + 1)\n",
    "    assert len(xticks) == len(x_histbins)\n",
    "    ax.set_xticks(xticks-0.501, minor=True)\n",
    "    ax.set_xticks(xticks[::4]-0.5)\n",
    "    ax.set_xticklabels(['$10^{' + f'{x/4-9}' + '}$' for x in xticks[::4]])\n",
    "\n",
    "    x_ticks, x_ticklabels = [], []\n",
    "    for i_tick, x_tick in enumerate(x_histbins):\n",
    "        xtlog1 = np.log10(x_tick)\n",
    "        if np.abs(xtlog1 - np.round(xtlog1)) < 0.001:\n",
    "            x_ticks.append(i_tick - 0.5)\n",
    "            x_ticklabels.append('$10^{' + f'{int(np.round(xtlog1))}' + '}$')\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_ticklabels)\n",
    "\n",
    "    yticks = np.arange(n_chem)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticks(yticks-0.5, minor=True)\n",
    "    ax.set_yticklabels(chem_species_str.split(','))\n",
    "\n",
    "    ax.grid(which='minor', color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "    # Remove minor ticks\n",
    "    ax.tick_params(which='minor', bottom=False, left=False)\n",
    "\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "    ax.set_xlabel('Diameter (m)')\n",
    "    ax.set_ylabel('Chemical Species')\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe697f8",
   "metadata": {},
   "source": [
    "# Plain Data without Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b643e",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "m_chmprthst20 = m_chmprthst.reshape(n_snr * n_t, n_chem, n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175e8c9",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt_data = m_chmprthst20.mean(axis=0).reshape(n_chem, n_bins)\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)\n",
    "ax.set_title('Plain Mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a04c5",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt_data = m_chmprthst20.std(axis=0).reshape(n_chem, n_bins)\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)\n",
    "ax.set_title('Plain Standard Deviation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe9d6b",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt_data = np.log10(m_chmprthst20.std(axis=0)).reshape(n_chem, n_bins)\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)\n",
    "ax.set_title('Log Standard Deviation');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e204ab",
   "metadata": {},
   "source": [
    "## Legacy Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48099dc2",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "pp_data(pp_id='legacy', eps=1e-25, exponent=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c0394",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=140, figsize=(5, 4))\n",
    "plt_data = np.log10(np.abs(m_chmprthst6))\n",
    "ax.hist(plt_data.ravel(), bins=17, range=[-17, 0], color='green', edgecolor='white', linewidth=2)\n",
    "xticks = [-16, -14, -12, -10,  -8,  -6,  -4,  -2,   0]\n",
    "ax.set_xticks(xticks)\n",
    "# xticks = ax.get_xticks()\n",
    "ax.set_xticklabels([r'$10^{'+ str(int(xx)) + r'}$' for xx in xticks])\n",
    "ax.set_xlabel(r'$std[\\tilde{x}]$')\n",
    "\n",
    "x_vline = np.quantile(plt_data, .622)\n",
    "ax.axvline(x=x_vline, ymin=0, ymax=0.98, lw=2, color='white', ls='--')\n",
    "ax.text(x_vline*0.9, 120, '     60th\\nPercentile',\n",
    "        bbox={'facecolor': 'black', 'pad': 2})\n",
    "ax.set_ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1384c",
   "metadata": {},
   "source": [
    "### The Unscaled Overall Variation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee77522",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt_data = m_chmprthst6.reshape(n_chem, n_bins)\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87052c8",
   "metadata": {},
   "source": [
    "### The Unscaled Overall Variation Heatmap (Log-scaled colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402d8ea",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt_data = np.log10(m_chmprthst6.reshape(n_chem, n_bins))\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1b24d",
   "metadata": {},
   "source": [
    "### Specific Scenario and Time-step Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160da517",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt_data = np.log10(m_chmprthst[2, 24])\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d24353",
   "metadata": {},
   "source": [
    "## Root Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2f32a",
   "metadata": {},
   "source": [
    "### The Final RMSE in each Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa077e4",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "pp_data(pp_id='root', eps=1e-225, exponent=1)\n",
    "plt_data = deepcopy(m_chmprthst15).reshape(n_chem, n_bins)\n",
    "# plt_data[[4, 10, 11, 12, 13, 15], :] = 0\n",
    "# plt_data[:, 0] = 0\n",
    "fig, ax = plot_heatmap(plt_data, x_histbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e21aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
