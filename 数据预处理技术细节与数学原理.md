# 数据预处理技术细节与数学原理

## 目录
1. [预处理模块架构](#预处理模块架构)
2. [基础变换操作](#基础变换操作)
3. [高级变换操作](#高级变换操作)
4. [参数推断机制](#参数推断机制)
5. [前向与反向变换](#前向与反向变换)
6. [预处理流水线](#预处理流水线)
   - [Particle-Resolved 预处理流程](#particle-resolved-预处理流程polyprt-模块)
   - [Bin-Resolved 预处理流程](#bin-resolved-预处理流程polyhst-模块)
7. [实际应用案例](#实际应用案例)
8. [Encoder输入与Decoder目标数据详解](#encoder输入与decoder目标数据详解)

---

## 预处理模块架构

### 核心组件

项目中的预处理系统基于 `PreProcessor` 类实现，该类继承自 `nn.Module`，采用有向无环图（DAG）结构来组织变换操作。

#### 1. 图结构表示

预处理流程被组织为一个DAG，其中：
- **节点（Layers）**：表示各种变换操作
- **边（Edges）**：表示数据流向
- **拓扑排序**：确保变换按正确顺序执行

```python
# 从 n22_utils.py 中的实现
class PreProcessor(nn.Module):
    def __init__(self, pp_config: dict, device, dtype, cdtype):
        # 解析配置，构建DAG
        pp_layers = self.parse_config(pp_config)
        # 拓扑排序
        pp_layers, invpp_ts = self.sort_topological(pp_layers)
```

#### 2. 层类型分类

根据可逆性，层被分为三类：

**可逆层（Invertible Layers）**：
- `add`, `mul`, `shift`, `scale`
- `log`, `exp`, `sgnpow`, `pwr`, `pow`
- `normalize`, `cdf`
- `cat`, `stack`, `reshape`

**不可逆层（Non-invertible Layers）**：
- `pnorm`（单独使用时）
- 各种 `torch.*` 函数（如 `torch.sum`, `torch.mean`）

**特殊层（Special Layers）**：
- `input`: 输入层
- `output`: 输出层
- `pipe`: 管道层（直接传递）

---

## 基础变换操作

### 1. 加法变换（Add）

**数学公式**：

$$
y = x + c
$$

**实现**：
```python
# 前向变换
layer_mb = layer_input + layer_value

# 反向变换
layer_mb = layer_outmb - layer_outvalue
```

**应用场景**：
- 添加小的常数（如 `cnteps = 1000`）避免零值问题
- 数据偏移调整

### 2. 乘法变换（Mul）

**数学公式**：

$$
y = x \cdot c
$$

**实现**：
```python
# 前向变换
layer_mb = layer_input * layer_value

# 反向变换
layer_mb = layer_outmb / layer_outvalue
```

**约束条件**：
- 反向变换要求 $c \neq 0$

### 3. 平移变换（Shift）

**数学公式**：

$$
y = x - \mu
$$

其中 $\mu$ 是从训练数据推断的均值。

**实现**：
```python
# 参数推断（infer阶段）
mb_valsmean = layer_inpmbvals.sum(dim=mb_order, keepdim=True) / n_trn
pp_params[f'{layer_name}/value'] = nn.Parameter(mb_valsmean)

# 前向变换
layer_mb = layer_input - pp_params[f'{layer_name}/value']

# 反向变换
layer_mb = layer_outmb + layer_outvalue
```

**数学原理**：
- **均值中心化**：将数据分布的中心移到原点
- **维度约简**：可以沿指定维度计算均值

  $$
  \mu_d = \frac{1}{N} \sum_{i=1}^{N} x_{i,d}
  $$

  其中 $d$ 是约简维度，$N$ 是样本数

### 4. 缩放变换（Scale）

**数学公式**：

$$
y = \frac{x}{\sigma + \epsilon}
$$

其中 $\sigma$ 是从训练数据推断的标准差（或p-范数），$\epsilon$ 是防止除零的小常数。

**实现**：
```python
# 参数推断
layer_pnorm = layer_opts.get('pnorm', 2)  # 默认L2范数
mb_valssqmean = layer_inpmbvals.abs().pow(layer_pnorm).sum(dim=mb_order, keepdim=True) / n_trn
layer_eps = layer_opts.get('eps', 0.0)
layer_parammean2 = (layer_eps ** layer_pnorm) + mb_valssqmean
pp_params[f'{layer_name}/value'] = nn.Parameter(layer_parammean2.pow(1.0 / layer_pnorm))

# 前向变换
layer_mb = layer_input / pp_params[f'{layer_name}/value']

# 反向变换
layer_mb = layer_outmb * layer_outvalue
```

**数学原理**：

**L2范数标准化（pnorm=2）**：

$$
\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} |x_i|^2 + \epsilon^2}
$$

**L1范数标准化（pnorm=1）**：

$$
\sigma = \frac{1}{N} \sum_{i=1}^{N} |x_i| + \epsilon
$$

**维度约简**：
- 可以沿指定维度计算范数
- 结果形状：约简维度变为1，其他维度保持不变

**数值稳定性**：
- $\epsilon$ 防止除零错误
- 对于L2范数：$\sigma = \sqrt{\mathbb{E}[x^2] + \epsilon^2}$

---

## 高级变换操作

### 1. 对数变换（Log）

**数学公式**：

$$
y = \frac{\ln(x)}{\ln(b)}
$$

其中 $b$ 是对数底数（默认为自然对数 $e$）。

**实现**：
```python
# 前向变换
layer_logbase = pp_params[f'{layer_name}/logbase']
layer_mb = layer_input / layer_logbase

# 反向变换
layer_mb = (layer_outmb * layer_outlogbase).exp()
```

**数学原理**：
- **对数变换**将乘法关系转换为加法关系
- **压缩大值**：对数值域压缩，适合处理跨度大的数据
- **可逆性**：要求 $x > 0$

**常见应用**：
- 处理粒子计数数据（添加epsilon后取对数）
- 处理质量分布数据

### 2. 指数变换（Exp）

**数学公式**：

$$
y = b^x
$$

**实现**：
```python
# 前向变换
layer_expbase = pp_params[f'{layer_name}/expbase']
layer_mb = (layer_input * layer_expbase).exp()

# 反向变换
layer_mb = layer_outmb.log() / layer_outexpbase
```

### 3. 符号保持幂变换（SgnPow）

**数学公式**：

$$
y = \text{sign}(x) \cdot |x|^{\alpha}
$$

**实现**：
```python
# 前向变换
layer_power = pp_params[f'{layer_name}/exponent']
layer_mb = layer_input.abs().pow(layer_power) * layer_input.sign()

# 反向变换
layer_mb = layer_outmb.abs().pow(1.0 / layer_outpower) * layer_outmb.sign()
```

**数学原理**：
- **保持符号**：对于负值，先取绝对值，应用幂次，再恢复符号
- **可处理负值**：与普通幂变换不同，可以处理负输入
- **常用幂次**：
  - $\alpha = 0.5$：平方根变换
  - $\alpha = 2$：平方变换
  - $\alpha < 1$：压缩大值，扩展小值

### 4. P-范数（PNorm）

**数学公式**：

$$
\|x\|_p = \left(\sum_{i} |x_i|^p\right)^{1/p}
$$

**实现**：
```python
# 前向变换
layer_dim = layer_opts['dim']  # 约简维度
layer_pnorm = layer_opts['pnorm']  # p值（1或2）
layer_mb = layer_input.abs().pow(layer_pnorm).sum(dim=layer_dim, keepdim=True).pow(1.0 / layer_pnorm)
```

**数学原理**：
- **L1范数（p=1）**：$\|x\|_1 = \sum_i |x_i|$
- **L2范数（p=2）**：$\|x\|_2 = \sqrt{\sum_i x_i^2}$
- **维度约简**：沿指定维度计算范数，该维度变为1

**应用场景**：
- 计算质量直方图的总体量级
- 用于后续的归一化操作

### 5. 归一化（Normalize）

**数学公式**：

$$
y = \frac{x}{\|x\|_p}
$$

**实现**：
```python
# 前向变换
layer_dim = layer_opts['dim']
layer_pnorm = layer_opts['pnorm']
layer_mb = layer_input / layer_input.norm(p=layer_pnorm, dim=layer_dim, keepdim=True)
```

**数学原理**：
- **单位向量化**：将向量归一化为单位向量
- **方向保持**：只改变大小，不改变方向
- **可逆性**：需要保存原始范数值才能完全恢复

**反向变换**：
```python
# 需要同时有归一化层和pnorm层
lyrnrmlz_mbpnrm = lyrnrmlz_mb.abs().pow(lyrpnrm_pnorm).sum(dim=lyrpnrm_dim, keepdim=True).pow(1./lyrpnrm_pnorm)
layer_mbnrmlzd = lyrnrmlz_mb / lyrnrmlz_mbpnrm
layer_mb = lyrpnrm_mb * layer_mbnrmlzd
```

### 6. 累积分布函数变换（CDF）

**数学公式**：

$$
y = F_X(x) = P(X \leq x)
$$

**实现**：
```python
# 参数推断：计算分位数
n_qnts = layer_opts['bins'] + 1
q_cdfs = torch.linspace(0, 1, n_qnts)
layer_qntls = torch_quantile(layer_alldata, q_cdfs, dim=cdf_dims, keepdim=True)

# 前向变换：线性插值
alpha = (x - q_lo) / (q_hi - q_lo)
y = alpha * F(q_hi) + (1 - alpha) * F(q_lo)

# 反向变换：逆CDF（分位数函数）
alpha3 = layer_cdfs3 - layer_cdfs3.floor()
layer_mb = alpha3 * srch_valshi2 + (1 - alpha3) * srch_valslo2
```

**数学原理**：
- **分位数估计**：使用训练数据估计分位数
- **线性插值**：在分位数之间进行线性插值
- **均匀化**：将任意分布映射到[0,1]均匀分布
- **可逆性**：通过逆CDF可以恢复原始分布

**分位数计算**：

$$
Q(p) = \inf\{x: F_X(x) \geq p\}
$$

**线性插值**：

$$
F_X(x) \approx F_X(q_i) + \frac{x - q_i}{q_{i+1} - q_i} \cdot (F_X(q_{i+1}) - F_X(q_i))
$$

---

## 参数推断机制

### 推断流程

参数推断（`infer`方法）用于从训练数据中自动计算 `shift`、`scale` 和 `cdf` 层的参数。

#### 1. 推断轮次（Rounds）

由于某些层（如 `shift`、`scale`）的参数依赖于前面层的输出，系统采用**多轮推断**机制：

```python
# 计算最大轮次
n_totrnds = max(pp_layers[layer_name]['round'] for layer_name in pp_layers)

for i_rnd in range(n_totrnds):
    # 只推断当前轮次的参数
    for layer_name, layer_opts in pp_layers.items():
        layer_round = layer_opts['round']
        if (i_rnd == layer_round - 1) and (layer_type in ('shift', 'scale', 'cdf')):
            # 推断参数
```

**轮次分配规则**：
- `input` 层：round = 0
- `shift`/`scale` 层：round = 输入层的round + 1
- 其他层：round = 输入层的round

#### 2. 均值推断（Shift）

**数学公式**：

$$
\mu = \frac{1}{N} \sum_{i=1}^{N} x_i
$$

**实现**：
```python
mb_valsmean = layer_inpmbvals.sum(dim=mb_order, keepdim=True) / n_trn
layer_parammean = layer_params.mean(dim=layer_dim, keepdim=True)  # 维度约简
```

**维度约简**：
- 可以沿指定维度计算均值
- 例如：`dim=[-1, -2]` 表示沿最后两个维度约简

#### 3. 标准差推断（Scale）

**L2范数（默认）**：

$$
\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} |x_i|^2 + \epsilon^2}
$$

**实现**：
```python
layer_pnorm = layer_opts.get('pnorm', 2)
mb_valssqmean = layer_inpmbvals.abs().pow(layer_pnorm).sum(dim=mb_order, keepdim=True) / n_trn
layer_eps = layer_opts.get('eps', 0.0)
layer_parammean2 = (layer_eps ** layer_pnorm) + mb_valssqmean
pp_params[f'{layer_name}/value'] = layer_parammean2.pow(1.0 / layer_pnorm)
```

**L1范数**：

$$
\sigma = \frac{1}{N} \sum_{i=1}^{N} |x_i| + \epsilon
$$

#### 4. CDF分位数推断

**实现**：
```python
# 收集所有mini-batch数据
layer_alldata = torch.cat(layer_params, dim=mb_order)

# 计算分位数
q_cdfs = torch.linspace(0, 1, n_qnts)
layer_qntls = torch_quantile(layer_alldata, q_cdfs, dim=cdf_dims, keepdim=True)

# 添加域边界
layer_qntls2 = torch.cat([
    torch.full(flshp, domain_min),  # 下界
    layer_qntls1,
    torch.full(flshp, domain_max)   # 上界
], dim=d_qtmp)
```

**数学原理**：
- **分位数定义**：$Q(p) = \inf\{x: F_X(x) \geq p\}$
- **线性插值**：在分位数之间使用线性插值
- **域扩展**：添加域边界确保所有值都在范围内

---

## 前向与反向变换

### 前向变换（Forward）

前向变换按照拓扑排序顺序执行：

```python
def forward(self, inputs_mb: dict, full: bool = False):
    # 拓扑排序后的层顺序
    for layer_name in pp_ts:
        layer_type = layer_opts['type']
        layer_input = layer_opts['input']
        
        # 根据类型执行变换
        if layer_type == 'add':
            layer_mb = layers_mb[layer_input] + pp_params[f'{layer_name}/value']
        elif layer_type == 'shift':
            layer_mb = layers_mb[layer_input] - pp_params[f'{layer_name}/value']
        # ... 其他变换
```

### 反向变换（Inverse）

反向变换按照逆拓扑排序顺序执行：

```python
def inverse(self, outputs_mb: dict, shaper=None, strict=True):
    # 逆拓扑排序
    for layer_name in invpp_ts:
        layer_outtype = layer_outopts['type']
        layer_output = layer_invinputs[0]
        
        # 根据类型执行逆变换
        if layer_outtype == 'add':
            layer_mb = layer_outmb - layer_outvalue
        elif layer_outtype == 'shift':
            layer_mb = layer_outmb + layer_outvalue
        # ... 其他逆变换
```

**可逆性约束**：
- `strict=True`：严格检查可逆性（如检查NaN、零值等）
- 某些变换（如 `normalize`）需要额外的信息才能完全恢复

---

## 预处理流水线

### Particle-Resolved 预处理流程（`polyprt` 模块）

`polyprt` 模块处理粒子级别的气溶胶数据，包含三个并行的预处理流程：

#### 第一部分：质量处理（Mass Processing）

**输入**：`m_prtchm` - 每个粒子的化学物质质量 `[n_seeds, n_mb, n_part, n_chem]`

1. **M1: 添加epsilon**：
   $$
   M_1 = m_{\text{prtchm}} + \epsilon_{\text{mss}}
   $$
   - 防止零值问题

2. **M2: 幂变换**：
   $$
   M_2 = M_1^{\alpha_{\text{mss}}}
   $$
   - 调整数据分布（常用 $\alpha = 0.5$，平方根变换）

3. **M3: 均值中心化**（可选）：
   $$
   M_3 = M_2 - \mu_2
   $$
   - 沿 `mssscldim` 维度计算均值
   - 如果 `mssscldim = 'n_len'`，则沿化学物质维度约简

4. **M4: 标准化**（可选）：
   $$
   M_4 = \frac{M_3}{\sigma_3 + \epsilon}
   $$
   - 输出：`m_prtchmnrm` - 归一化后的粒子质量
   - **这是送入encoder的质量数据**

#### 第二部分：权重处理（Weight Processing）

**输入**：`w_prt` - 每个粒子的权重 `[n_seeds, n_mb, n_part, 1]`

1. **W1: 添加epsilon**：
   $$
   W_1 = w_{\text{prt}} + \epsilon_{\text{wgt}}
   $$

2. **W2: 幂变换**：
   $$
   W_2 = W_1^{\alpha_{\text{wgt}}}
   $$
   - 通常 $\alpha_{\text{wgt}} = 1$（不变换）

3. **W3: 均值中心化**（可选）：
   $$
   W_3 = W_2 - \mu_2
   $$
   - 沿 `[-2, -1]` 维度（粒子和通道维度）计算均值

4. **W4: 标准化**（可选）：
   $$
   W_4 = \frac{W_3}{\sigma_3 + \epsilon}
   $$
   - 使用L1或L2范数计算 $\sigma_3$
   - 输出：`w_prtonenrm` - 归一化后的粒子权重
   - **这是送入encoder的权重数据**

#### 第三部分：总计数处理（Total Count Processing）

**输入**：`n_tot` - 总粒子计数 `[n_seeds, n_mb, 1, 1]`

1. **T1: 添加epsilon**：
   $$
   T_1 = n_{\text{tot}} + \epsilon_{\text{tot}}
   $$
   - 通常 $\epsilon_{\text{tot}} = 1000$（较大值，避免零计数）

2. **T2: 幂变换**：
   $$
   T_2 = T_1^{\alpha_{\text{tot}}}
   $$
   - 通常 $\alpha_{\text{tot}} = 1$（不变换）

3. **T3: 均值中心化**（可选）：
   $$
   T_3 = T_2 - \mu_2
   $$
   - 沿 `[-2, -1]` 维度计算均值

4. **T4: 标准化**（可选）：
   $$
   T_4 = \frac{T_3}{\sigma_3 + \epsilon}
   $$
   - 使用L1或L2范数计算 $\sigma_3$
   - 输出：`n_totpopnrm` - 归一化后的总计数
   - **这是送入encoder的总计数数据**

**配置示例**（`configs/03_prtcls/02_mlpprt.yml`）：
```yaml
nn/pp/enc/type: polyprt
nn/pp/enc/msseps: 1e-100
nn/pp/enc/mssexp: 0.5        # 平方根变换
nn/pp/enc/mssshft: 'on'      # 启用均值中心化
nn/pp/enc/mssscl: 'on'       # 启用标准化
nn/pp/enc/mssscldim: 'n_len' # 沿化学物质维度约简

nn/pp/enc/wgteps: 1e-100
nn/pp/enc/wgtexp: 1          # 不变换
nn/pp/enc/wgtshft: 'off'     # 不中心化
nn/pp/enc/wgtscl: 'on'       # 启用标准化

nn/pp/enc/toteps: 1000
nn/pp/enc/totexp: 1          # 不变换
nn/pp/enc/totshft: 'on'      # 启用均值中心化
nn/pp/enc/totscl: 'on'       # 启用标准化
```

### Bin-Resolved 预处理流程（`polyhst` 模块）

以气溶胶直方图数据为例（`polyhst` 模块）：

#### 第一部分：质量（Mass）处理

1. **添加epsilon**：

   $$
   M_1 = M_0 + \epsilon
   $$

2. **计算Lp范数**：

   $$
   M_2 = \|M_1\|_p
   $$

3. **幂变换**：

   $$
   M_3 = M_2^{\alpha}
   $$

4. **均值中心化**（可选）：

   $$
   M_4 = M_3 - \mu_3
   $$

5. **标准化**（可选）：

   $$
   M_5 = \frac{M_4}{\sigma_4 + \epsilon}
   $$

#### 第二部分：归一化（Normalization）

1. **归一化**：

   $$
   M_6 = \frac{M_1}{M_2} = \frac{M_1}{\|M_1\|_p}
   $$

2. **幂变换**：

   $$
   M_7 = M_6^{\alpha}
   $$

3. **均值中心化**（可选）：

   $$
   M_8 = M_7 - \mu_7
   $$

4. **标准化**（可选）：

   $$
   M_9 = \frac{M_8}{\sigma_8 + \epsilon}
   $$

#### 第三部分：计数（Count）处理

1. **添加epsilon**：

   $$
   N_1 = N_0 + \epsilon
   $$

2. **幂变换**：

   $$
   N_2 = N_1^{\alpha}
   $$

3. **均值中心化**（可选）：

   $$
   N_3 = N_2 - \mu_2
   $$

4. **标准化**（可选）：

   $$
   N_4 = \frac{N_3}{\sigma_3 + \epsilon}
   $$

### 配置示例

```yaml
ppmodules/polyhst:
  input:
    m_chmprthst: [n_seeds, n_mb, n_chem, n_bins]
    n_prthst:    [n_seeds, n_mb, 1, n_bins]
  
  hparams:
    nrmeps: 1e-100      # 质量epsilon
    magpnrm: 2          # L2范数
    magexp: null        # 质量幂次
    magshft: true       # 是否中心化
    magscl: true        # 是否标准化
    cnteps: 1000        # 计数epsilon
    cntexp: null        # 计数幂次
    # ... 其他参数
```

---

## 实际应用案例

### 案例1：质量直方图预处理

**输入**：`m_chmprthst` - 化学物质质量分布直方图

**处理流程**：
1. 添加小epsilon避免零值
2. 计算L2范数得到总质量
3. 归一化得到质量分数
4. 应用幂变换调整分布
5. 中心化和标准化

**数学表示**：

$$
\begin{align}
M_1 &= M_0 + \epsilon \\
M_2 &= \|M_1\|_2 \\
M_6 &= \frac{M_1}{M_2} \\
M_7 &= M_6^{\alpha} \\
M_8 &= M_7 - \mu_7 \\
M_9 &= \frac{M_8}{\sigma_8 + \epsilon}
\end{align}
$$

### 案例2：计数数据预处理

**输入**：`n_prthst` - 粒子计数直方图

**处理流程**：
1. 添加较大epsilon（如1000）避免零计数
2. 应用对数或幂变换
3. 中心化和标准化

**数学表示**：

$$
\begin{align}
N_1 &= N_0 + \epsilon \\
N_2 &= N_1^{\alpha} \quad \text{或} \quad \ln(N_1) \\
N_3 &= N_2 - \mu_2 \\
N_4 &= \frac{N_3}{\sigma_3 + \epsilon}
\end{align}
$$

### 案例3：条件VAE标签生成

**输入**：`m_chmprthst` - 化学物质质量分布

**处理流程**：
1. 计算每种化学物质的总质量
2. 计算质量分数
3. 选择特定化学物质（如OIN）
4. 计算CDF
5. 分位数分类

**数学表示**：

$$
\begin{align}
M_{\text{total}} &= \sum_{\text{bins}} M_{\text{chem}} \\
M_{\text{frac}} &= \frac{M_{\text{chem}}}{M_{\text{total}}} \\
F(x) &= P(M_{\text{frac}} \leq x) \\
\text{Label} &= \lfloor F(x) \cdot n_{\text{bins}} \rfloor
\end{align}
$$

---

## 总结

### 核心设计原则

1. **可逆性**：大多数变换都是可逆的，支持从输出恢复输入
2. **参数推断**：自动从训练数据推断参数（均值、标准差、分位数）
3. **维度灵活性**：支持沿任意维度进行约简操作
4. **数值稳定性**：使用epsilon防止除零和数值溢出

### 数学基础

- **线性代数**：范数、归一化、矩阵运算
- **概率论**：CDF、分位数、统计量
- **数值分析**：插值、数值稳定性

### 实现特点

- **图结构**：DAG表示变换流程
- **拓扑排序**：确保正确执行顺序
- **批处理**：支持mini-batch处理
- **缓存机制**：参数推断结果可缓存

---

## Encoder输入与Decoder目标数据详解

### 数据流概览

在 `vaepart.py` 的训练流程中，数据经过以下处理：

```
原始数据 → Encoder预处理 → Encoder → 潜在空间 → Decoder → Decoder预处理 → 重建损失计算
```

### Particle-Resolved（粒子级别）数据流程

**重要说明**：`vaepart.py` 处理的是 **particle-resolved aerosol state**（粒子级别的气溶胶状态），而不是bin-resolved（直方图级别）的状态。

#### Encoder的输入数据（Particle-Resolved）

**原始输入**（从数据文件加载，粒子级别）：
- `m_prtchm`: 每个粒子的化学物质质量 `[n_seeds, n_mb, n_part, n_chem]`
  - `n_part`: 每个气溶胶群体中的粒子数量（如1000个粒子）
  - `n_chem`: 化学物质种类数（如15种）
- `w_prt`: 每个粒子的权重 `[n_seeds, n_mb, n_part, 1]`
- `n_tot`: 总粒子计数 `[n_seeds, n_mb, 1, 1]`

**Encoder预处理**（`enc_pp`，类型：`polyprt`）：

`polyprt` 模块对粒子级别数据进行预处理，包含三个并行流程：

##### 1. 质量处理流程（M1 → M4）

1. **M1: 添加epsilon**
   $$
   M_1 = m_{\text{prtchm}} + \epsilon_{\text{mss}}
   $$
   - 输入：`m_prtchm` `[n_seeds, n_mb, n_part, n_chem]`
   - 输出：`m01` `[n_seeds, n_mb, n_part, n_chem]`

2. **M2: 幂变换**
   $$
   M_2 = M_1^{\alpha_{\text{mss}}}
   $$
   - 输出：`m02` `[n_seeds, n_mb, n_part, n_chem]`

3. **M3: 均值中心化**（可选）
   $$
   M_3 = M_2 - \mu_2
   $$
   - 沿 `mssscldim` 维度计算均值
   - 输出：`m03` `[n_seeds, n_mb, n_part, n_chem]`

4. **M4: 标准化**（可选）
   $$
   M_4 = \frac{M_3}{\sigma_3 + \epsilon}
   $$
   - 输出：`m_prtchmnrm` (M4) `[n_seeds, n_mb, n_part, n_chem]`
   - **这是送入encoder的质量数据**

##### 2. 权重处理流程（W1 → W4）

1. **W1: 添加epsilon**
   $$
   W_1 = w_{\text{prt}} + \epsilon_{\text{wgt}}
   $$
   - 输入：`w_prt` `[n_seeds, n_mb, n_part, 1]`

2. **W2: 幂变换**
   $$
   W_2 = W_1^{\alpha_{\text{wgt}}}
   $$

3. **W3: 均值中心化**（可选）
   $$
   W_3 = W_2 - \mu_2
   $$
   - 沿 `[-2, -1]` 维度计算均值

4. **W4: 标准化**（可选）
   $$
   W_4 = \frac{W_3}{\sigma_3 + \epsilon}
   $$
   - 输出：`w_prtonenrm` (W4) `[n_seeds, n_mb, n_part, 1]`
   - **这是送入encoder的权重数据**

##### 3. 总计数处理流程（T1 → T4）

1. **T1: 添加epsilon**
   $$
   T_1 = n_{\text{tot}} + \epsilon_{\text{tot}}
   $$
   - 输入：`n_tot` `[n_seeds, n_mb, 1, 1]`

2. **T2: 幂变换**
   $$
   T_2 = T_1^{\alpha_{\text{tot}}}
   $$

3. **T3: 均值中心化**（可选）
   $$
   T_3 = T_2 - \mu_2
   $$
   - 沿 `[-2, -1]` 维度计算均值

4. **T4: 标准化**（可选）
   $$
   T_4 = \frac{T_3}{\sigma_3 + \epsilon}
   $$
   - 输出：`n_totpopnrm` (T4) `[n_seeds, n_mb, 1, 1]`
   - **这是送入encoder的总计数数据**

**最终送入Encoder的数据**（`vaepart.py` 第878-911行）：
```python
# Encoder预处理
ue_mbs, ue_shaper = enc_pp.forward(xe_mbs, full=False)
# ue_mbs包含：
#   - m_prtchmnrm: [n_seeds, n_mb, n_part, n_chem]  (M4)
#   - w_prtonenrm: [n_seeds, n_mb, n_part, 1]        (W4)
#   - n_totpopnrm: [n_seeds, n_mb, 1, 1]            (T4)

# 送入Encoder
musig_mbs = encoder(**ue_mbs, **y_mbs)
```

**Encoder架构特点**（`mlpencprt`）：
- 使用**Deep Set**架构处理粒子集合
- 对每个粒子应用MLP：`m_prtchmnrm` → MLP → 中间表示
- 使用权重 `w_prtonenrm` 对粒子进行加权平均
- 最终输出潜在空间的均值和方差

### Decoder的输出目标数据（Bin-Resolved，直方图级别）

**重要说明**：虽然Encoder处理的是particle-resolved数据，但Decoder输出的是**bin-resolved（直方图级别）**的数据。这是VAE的设计：从粒子级别编码到潜在空间，然后解码为直方图表示。

**Decoder直接输出**（`mlpdecprt` 网络，`vaepart.py` 第1145行）：
```python
udhat_tmbs = decoder(**z_tmbs, **y_mbs)
```

Decoder网络直接输出以下预处理后的数据（在u空间）：
- `m_chmprtnrm`: `[n_seeds, n_mb, n_chem, n_bins]` - 归一化质量直方图
- `m_prthstmag`: `[n_seeds, n_mb, n_chnlsmag, n_binsmag]` - 质量大小
- `n_prthstnrm`: `[n_seeds, n_mb, 1, n_bins]` - 归一化计数直方图
- `c_ccnpopnrm`: `[n_seeds, n_mb, 1, n_epshist]` - CCN谱
- `s_optpopnrm`: `[n_seeds, n_mb, 1, n_wave]` - 光学散射谱
- `a_optpopnrm`: `[n_seeds, n_mb, 1, n_wave]` - 光学吸收谱
- `f_inppopnrm`: `[n_seeds, n_mb, 1, n_tmprtr]` - 冻结分数谱
- `n_totpopnrm`: `[n_seeds, n_mb, 1, 1]` - 总计数

**Decoder预处理**（`dec_pp`，类型：`polydiag`）：

`polydiag` 模块定义了从原始直方图数据到这些输出的预处理流程。对于质量数据，流程与 `polyhst` 相同：

1. **`m_chmprtnrm`** (对应 `polyhst` 的 **M9**)：
   - 处理流程：M1 → M2(pnorm) → M6(normalize) → M7(幂变换) → M8(均值中心化) → **M9(标准化)**
   - 这是**归一化后的质量直方图** `[n_seeds, n_mb, n_chem, n_bins]`
   - 数学表示：
     $$
     M_9 = \frac{M_8}{\sigma_8 + \epsilon}, \quad M_8 = M_7 - \mu_7
     $$

2. **`m_prthstmag`** (对应 `polyhst` 的 **M5**)：
   - 处理流程：M1 → M2(pnorm) → M3(幂变换) → M4(均值中心化) → **M5(标准化)**
   - 这是**质量的大小（magnitude）** `[n_seeds, n_mb, n_chnlsmag, n_binsmag]`
   - 数学表示：
     $$
     M_5 = \frac{M_4}{\sigma_4 + \epsilon}, \quad M_4 = M_3 - \mu_3
     $$

3. **`n_prthstnrm`** (对应 `polyhst` 的 **N4**)：
   - 处理流程：N1(添加epsilon) → N2(幂变换) → N3(均值中心化) → **N4(标准化)**
   - 这是**归一化后的计数直方图** `[n_seeds, n_mb, 1, n_bins]`
   - 数学表示：
     $$
     N_4 = \frac{N_3}{\sigma_3 + \epsilon}, \quad N_3 = N_2 - \mu_2
     $$

**代码位置**（`vaepart.py` 第1145-1152行）：
```python
udhat_tmbs = decoder(**z_tmbs, **y_mbs)  # decoder直接输出u空间数据
# 如果需要逆变换到x空间（原始直方图数据）
if ppcri_inpspc == 'x':
    xdhat_tmbs = dec_pp.inverse(udhat_tmbs, ue_shaper, strict=True, full=False)
```

### 重建损失计算的目标数据

**损失计算配置**（`configs/03_prtcls/02_mlpprt.yml`）：
- `cri/rcnst/ppinp/space: u` - 在u空间计算损失
- `cri/rcnst/pp/type: udiagidentity` - 使用identity预处理（不改变数据）

**实际计算的数据**（`vaepart.py` 第1194-1204行）：
```python
# 原始数据经过dec_pp预处理
ud_tmbs, ud_shaper = dec_pp.forward(xd_tmbs, full=False)

# 通过cri_pp（udiagidentity）处理
uc_tmbs = cri_pp.forward(ud_tmbs, full=False)      # 目标数据
uchat_tmbs = cri_pp.forward(udhat_tmbs, full=False) # decoder重建数据

# 计算损失
uhat_terr = uc_tmbs - uchat_tmbs
```

**因此，重建损失计算的是以下数据的差异**：
- `m_chmprtnrm` (M9) - 归一化后的质量直方图
- `m_prthstmag` (M5) - 质量大小
- `n_prthstnrm` (N4) - 归一化后的计数直方图

### Particle-Resolved vs Bin-Resolved 数据转换

**关键设计**：VAE实现了从particle-resolved到bin-resolved的转换

```
Particle-Resolved (输入)          Bin-Resolved (输出)
───────────────────────          ───────────────────
m_prtchm [n_part, n_chem]   →    m_chmprthst [n_chem, n_bins]
w_prt    [n_part, 1]        →    n_prthst    [1, n_bins]
n_tot    [1, 1]              →    (保持不变)
```

**转换过程**：
1. **Encoder阶段**：将粒子集合编码为潜在表示
   - 使用Deep Set架构处理无序粒子集合
   - 每个粒子独立通过MLP，然后加权平均
   
2. **Decoder阶段**：从潜在表示解码为直方图
   - 直接输出直方图bin的数据
   - 不恢复单个粒子的信息

### 总结

| 阶段 | 数据 | 对应预处理层 | 数据级别 | 说明 |
|------|------|-------------|---------|------|
| **Encoder输入** | `m_prtchmnrm`, `w_prtonenrm`, `n_totpopnrm` | `polyprt` 的 M4, W4, T4 | **Particle-Resolved** | 粒子级别的归一化数据 `[n_part, n_chem]` |
| **Decoder输出** | `m_chmprtnrm`, `m_prthstmag`, `n_prthstnrm` | `polyhst` 的 **M9, M5, N4** | **Bin-Resolved** | 直方图级别的归一化数据 `[n_chem, n_bins]` |
| **损失计算** | 同上（M9, M5, N4） | `udiagidentity` | **Bin-Resolved** | 在u空间直接计算MSE/MAE |

**关键点**：
1. **Encoder处理的是particle-resolved数据**：
   - 输入：每个粒子的化学物质质量 `[n_part, n_chem]`
   - 输入：每个粒子的权重 `[n_part, 1]`
   - 使用Deep Set架构处理无序粒子集合

2. **Decoder输出的是bin-resolved数据**：
   - 输出：按直径bin分组的质量直方图 `[n_chem, n_bins]`
   - 输出：按直径bin分组的计数直方图 `[1, n_bins]`
   - 不恢复单个粒子的信息

3. **重建损失计算的是bin-resolved数据**：
   - 直接计算 **M9（归一化质量直方图）、M5（质量大小）、N4（归一化计数直方图）** 的差异
   - 在u空间（预处理后空间）计算，避免逆变换的数值误差

4. **数据维度转换**：
   - 粒子维度 `n_part`（如1000）→ 直方图维度 `n_bins`（如19）
   - 这种转换使得模型可以学习从粒子集合到统计分布的映射

---

## 参考文献

1. 项目代码：`partnn/notebooks/n22_utils.py` - `PreProcessor` 类
2. 配置文件：`configs/*/02_pp.yml` - 预处理模块配置
3. 主训练脚本：`partnn/vaepart.py` - 预处理集成

